---
title: 視線追跡
description: HoloLens 2 では、開発者がユーザーの注目に関する情報を使用できるようにすることで、holographic experience 内で新しいレベルのコンテキストと人間の理解を実現できます。
author: sostel
ms.author: sostel
ms.date: 10/29/2019
ms.topic: article
keywords: 視線追跡、mixed reality、インプット、視線、調整、mixed reality ヘッドセット、windows mixed reality ヘッドセット、virtual reality ヘッドセット、HoloLens、MRTK、Mixed Reality Toolkit、インテント、アクション
ms.openlocfilehash: c6167fc48a98de8f400400475c2057a2b4773b29
ms.sourcegitcommit: 4f3ef057a285be2e260615e5d6c41f00d15d08f8
ms.translationtype: MT
ms.contentlocale: ja-JP
ms.lasthandoff: 11/17/2020
ms.locfileid: "94702588"
---
# <a name="eye-tracking-on-hololens-2"></a>HoloLens 2 上の視線追跡

![MRTK の視線追跡デモ](images/mrtk_et_scenemenu.jpg)

HoloLens 2 では、開発者がユーザーの注目に関する情報を使用できるようにすることで、holographic experience 内で新しいレベルのコンテキストと人間の理解を実現できます。 このページでは、開発者がさまざまなユースケースについて視線追跡を利用する方法について説明します。また、視線を使用したユーザー操作を設計する際には、どのような利点があるかを説明します。 

アイ tracking API は、ユーザーのプライバシーを考慮して設計されており、特定可能な情報 (特に生体認証) を通過することを回避しています。 視線を追跡できるアプリケーションの場合、ユーザーは、視線追跡情報を使用するためのアクセス許可をアプリに付与する必要があります。 


### <a name="device-support"></a>デバイス サポート
<table>
<colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
</colgroup>
<tr>
     <td><strong>機能</strong></td>
     <td><a href="../hololens-hardware-details.md"><strong>HoloLens (第 1 世代)</strong></a></td>
     <td><a href="https://docs.microsoft.com/hololens/hololens2-hardware"><strong>HoloLens 2</strong></td>
     <td><a href="../discover/immersive-headset-hardware-details.md"><strong>イマーシブ ヘッドセット</strong></a></td>
</tr>
<tr>
     <td>視線</td>
     <td>❌</td>
     <td>✔️</td>
     <td>❌</td>
</tr>
</table>

<br>

## <a name="calibration"></a>調整 
視線追跡を正確に機能させるには、各ユーザーが、一連の holographic ターゲットを確認する必要がある、 [目の追跡ユーザーの調整](../calibration.md) を行う必要があります。 これにより、デバイスはシステムを調整して、より快適で品質の高い閲覧エクスペリエンスをユーザーに提供し、同時に正確な視点を追跡することができます。 

視線追跡はほとんどのユーザーに対して機能しますが、ユーザーが正常に調整できない場合もまれにあります。 調整は次のようなさまざまな理由で失敗する可能性があります。 
* ユーザーが以前に調整プロセスをオプトアウトした
* ユーザーが調整ターゲットに従わなかったため、
* ユーザーは、システムでまだサポートされていない特定の種類のコンタクトレンズとグラスを持っています。 
* ユーザーは、システムでまだサポートされていない、目の physiology、目の状態、または目のような問題を抱えています。  
* 外部要因は、損なわれるの前にヘアがあることが原因で、HoloLens バイザーや眼鏡に汚れが出たり、occlusions が非常に強い日光やになったりするなど、信頼性の高い視線を追跡します。

開発者は、視線追跡データが使用できない (正常に調整できない) ユーザーに対して十分なサポートを提供する必要があります。 このページの下部にあるセクションで、フォールバックソリューションに関する推奨事項を提供しています。 

調整の詳細と、スムーズなエクスペリエンスを保証する方法の詳細については、「 [ユーザーの調整](../calibration.md) の監視」ページをご覧ください。

<br>

## <a name="available-eye-tracking-data"></a>利用可能なアイトラッキングデータ
目を見つめた入力の特定のユースケースについて詳しく説明する前に、HoloLens 2 [目の追跡 API](https://docs.microsoft.com/uwp/api/windows.perception.people.eyespose) によって提供される機能について簡単に説明します。 開発者は約 _30 FPS (30 Hz)_ で、1つの目を見つめた射線 (宝石の出発点と向き) にアクセスできます。
視線追跡データへのアクセス方法の詳細については、「開発者ガイド」を参照してください。 [DirectX での視線](../develop/native/gaze-in-directx.md) と、 [Unity で](https://aka.ms/mrtk-eyes)の視線の使用に関するガイドを参照してください。

予測された視線は、実際のターゲットを中心に約1.5 °の範囲で表示されます (次の図を参照してください)。 わずかな不正確性が想定されているため、開発者はこの下限値に対していくらかの余白を計画する必要があります (たとえば、2.0-3.0 度では、より快適なエクスペリエンスが得られる可能性があります)。 以下では、小規模なターゲットの選択に対処する方法について説明します。 視線追跡が正しく機能するためには、各ユーザーが視線追跡ユーザー調整を行う必要があります。 

![2 m の距離での最適なターゲット サイズ](images/gazetargeting-size-1000px.jpg)<br>
*2メートル距離で最適なターゲットサイズ*

<br>

## <a name="use-cases"></a>ユース ケース
視線追跡を使用すれば、アプリケーションは、ユーザーが見ている場所をリアルタイムで追跡できます。 次のユースケースでは、2つの混合現実の HoloLens 2 での視線追跡によって可能な相互作用について説明します。
これらのユースケースはまだ Holographic シェルエクスペリエンスの一部ではないことに注意してください (つまり、HoloLens 2 を起動したときに表示されるインターフェイス)。
これらのいくつかは、 [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html)で試してみることができます。このツールキットでは、ざっと見てサポートされているターゲット選択など、目を通してテキストを自動的にスクロールするだけでなく、視線の追跡を使用するための便利で強力な例がいくつか提供されています。 

### <a name="user-intent"></a>ユーザーの目的    
ユーザーがどこで見ているかについての情報は、音声、ハンド、コントローラーなど **の他の入力に対し** て強力なコンテキストを提供します。
これは、さまざまなタスクに利用できます。
たとえば、ホログラムを見て *「選択」* ( **targeting** 「"選択"」を参照して [ください) また](gaze-and-commit.md)は *「この* ようにしてください」と言うと、ユーザーがホログラムを配置しようとしている場所に移動して、" *..."* この例は、「[Mixed Reality Toolkit - Eye-supported Target Selection (Mixed Reality Toolkit - 目で支援するターゲット選択)](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html)」と「[Mixed Reality Toolkit - Eye-supported Target Positioning (Mixed Reality Toolkit - 目で支援するターゲット配置)](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html)」に記載されています。

さらに、ユーザーの目的の例として、ユーザーが参照する情報を使用して、埋め込み仮想エージェントや対話型ホログラムによるエンゲージメントを強化することができます。 たとえば、仮想エージェントは、現在表示されているコンテンツに基づいて、使用可能なオプションとその動作を適合させる場合があります。 

### <a name="implicit-actions"></a>暗黙的アクション
暗黙的アクションのカテゴリは、ユーザー意図に密接に関係しています。
考えられるのは、ホログラムまたはユーザーインターフェイスの要素は、ユーザーがシステムと対話しているのではなく、システムとユーザーが同期しているのではなく、instinctual な方法で対応できるということです。一例として、ユーザーがテキストを読み取った後に、ユーザーがテキストボックスの一番下に移動すると自動的にスクロールを開始し、指を離さずにユーザーが読み取りフローを維持できるようにする、 **視線に基づく自動スクロール** があります。  
この重要な点は、スクロール速度がユーザーの読み取り速度に適応することです。
もう1つの例として、視線がサポートされている **ズームとパン** があります。ユーザーは、フォーカスされている内容を正確に把握することができます。 ズーム速度のトリガーと制御は、音声入力または手書き入力によって制御できます。これは、ユーザーがコントロールの感覚を持つことができるようにするために重要です。 これらの設計の考慮事項については、以下で詳しく説明します。 拡大した後、ユーザーは、目を見つめて使用するだけで、自宅などの道をスムーズにたどることができます。
この種の相互作用に関するデモの例は、「[Mixed Reality Toolkit - Eye-supported Navigation (Mixed Reality Toolkit - 目で支援するナビゲーション)](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html)」のサンプルを参照してください。

その他の _暗黙的アクション_ の使用事例を以下に示します。
- **スマート通知:** 通知によって annoyed が表示されます。 ユーザーがどのようなことに注目しているかを考慮して、ユーザーが現在使用している場所から通知をオフセットすることで、このエクスペリエンスを向上させることができます。 これにより、取られるが制限され、ユーザーの読み取りが完了すると自動的に破棄されます。 
- **Attentive ホログラム:** Gazed 時に微妙に反応するホログラム。 これは、少し発光した UI 要素、低速の咲きの花から仮想犬までの範囲であり、ユーザーが戻ってきて、その尾を wagging ます。 この相互作用によって、アプリケーションでの接続性と満足度がわかりやすくなる場合があります。

### <a name="attention-tracking"></a>注意追跡   
どこで、どのようなユーザーが見ているかについては、非常パワフルなツールです。 これにより、設計の使いやすさを評価し、ワークフローの問題を特定して効率を高めることができます。
さまざまなアプリケーション領域では、視線追跡の視覚化と分析が一般的な方法です。 HoloLens 2 では、このことを理解するために新しいディメンションを提供しています。これは、3D ホログラムを実際のコンテキストで配置し、それに従って評価することができるためです。 [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html)には、視線追跡データをログに記録して読み込む方法と、それらを視覚化する方法の基本的な例が用意されています。
Microsoft は、イノベーションを促進することを専門としています。また、視線追跡情報の使用方法について、ユーザーに情報を提供し、透過的なエクスペリエンスを提供しています。  マイクロソフトの開発者や UX チームと協力して、ユーザーの周囲にエクスペリエンスを中央に配置するためのガイダンスをサードパーティに提供します。  


この分野の他の適用方法を以下に示します。 
-   **リモートの視線可視化:** リモートの視線視覚エフェクト: リモートコラボレーターが見ているものを視覚化し、すぐにフィードバックを提供し、より正確な情報処理を促進できるようにします。
-   **ユーザー調査研究:** アテンション追跡を使用すると、研究者は、ユーザーのコンピューター間の instinctual 対話を設計するために干渉することなく、自然な環境をユーザーがどのように認識して関与するかについて、より多くの洞察を得ることができます。 視線追跡では、調査の参加者によって直接的には得られない情報を提供できます。この情報は、研究者によって簡単に見逃しられる可能性があります。 
-   **トレーニングとパフォーマンスの監視:** 実行フローでボトルネックをより効果的に識別することで、タスクの実行を実践および最適化します。 視線追跡は、職場でのトレーニング、生産性、および安全性を向上させるために、自然でリアルタイムの目標情報を提供することができます。 
-   **設計の評価、マーケティング、および消費者の調査:** 視線追跡を使用すると、商用の企業は、実際の環境でマーケティングや消費者の調査を実行したり、ユーザーの注目を集めて製品や領域の設計を向上させたり分析したりすることができます。 

### <a name="additional-use-cases"></a>その他の使用事例
- **ゲーム:** スーパーパワーが必要でしたか。 こつをお教えしましょう。 ホログラムを levitate することで、ホログラムを作成できます。 お客様の目からレーザービームを撮影してください。 [RoboRaid For HoloLens 2](https://www.microsoft.com/p/roboraid/9nblggh5fv3j)で試してみてください。
敵を石にするか、固定します。 透視能力を使ってビルを探索します。 使い道は想像力次第です。
ユーザーが圧倒されないことに注意してください。詳細については、「 [目を見つめた入力のデザインガイドライン](eye-gaze-interaction.md)」を参照してください。

- **表現力のあるアバター:** 視線追跡では、ライブ視線追跡データを使用して、ユーザーがどのようなものかを示すアバターの目をアニメーション化することで、より表現力の高い3D アバターを支援します。 

- **テキスト入力:** 視力の追跡は、特に音声や手の使用が不便な場合に、低労力のテキスト入力の代替手段として使用できます。 

<br>

## <a name="using-eye-gaze-for-interaction"></a>相互作用のための視線の使用
高速移動の視点を利用する相互作用を構築するのは困難な場合があります。
ワンハンドでは、視線の入力を使用する方法に注意する必要があるほど高速に移動します。そうしないと、ユーザーにとっては膨大な経験や邪魔が見られる可能性があるからです。 一方で、ユーザーに楽しみな気持ちする真のエクスペリエンスを作成することもできます。 詳細については、主な利点、課題、および [相互作用の](eye-gaze-interaction.md)ための視線の設計に関する推奨事項の概要に関する記事をご覧ください。 
 
## <a name="fallback-solutions-when-eye-tracking-is-not-available"></a>視線追跡が使用できない場合のフォールバックソリューション

まれに、視線追跡データが使用できない場合があります。
これには、次のようなさまざまな理由が考えられます。
* システムはユーザーを [調整](../calibration.md)できませんでした。
* ユーザーが [調整](../calibration.md)をスキップしました。    
* ユーザーは調整されていますが、目の追跡データを使用するためのアクセス許可をアプリに付与しないことに決定しました。    
* このユーザーには、システムがまだサポートしていない、固有の眼鏡またはいくつかの目の状態があります。    
* 外部要因は、損なわれるの前に髪があることから、HoloLens バイザーや眼鏡での汚れや occlusions の強い日光となど、信頼性の高い視線を追跡します。   

そのため、開発者は、これらのユーザーに適切なフォールバックサポートがあることを確認する必要があります。 「 [DirectX の目の追跡」](../develop/native/gaze-in-directx.md#fallback-when-eye-tracking-is-not-available) ページでは、視線追跡データが使用可能かどうかを検出するために必要な api について説明します。 

一部のユーザーは、目の追跡データへのアクセスを取り消すことを決定した場合がありますが、ユーザーエクスペリエンスの低下によって、視線追跡データへのアクセスを提供しないというプライバシーに対しては、これが意図していない場合があります。  
そのため、アプリが目の追跡を使用していて、これがエクスペリエンスの重要な部分である場合は、これをユーザーに明確に伝えることをお勧めします。     
アプリケーションの可能性を最大限に活用するために、目の追跡がアプリケーションにとって重要である理由をユーザーに通知します (一部の拡張機能が一覧表示されている場合もあります)。これにより、ユーザーが何をしているかをより深く理解することができます。   
上のチェックに基づいて、目の追跡が機能していない理由をユーザーが特定し、潜在的な問題の迅速なトラブルシューティングを行うための提案を提示します。     
たとえば、システムが目の追跡をサポートしていることを検出できた場合は、ユーザーが調整され、アクセス許可が与えられていても、目の追跡データが表示されないことがあります。これは、汚れや目の occluded など、他の問題を指している可能性があります。    
視線追跡が機能しない可能性があるユーザーはめったにないことに注意してください。   
そのため、では、アプリで目の追跡を有効にするためのアラームを消したり、無効にしたりできるようにすることで、このことを敬意してください。

### <a name="fallback-for-apps-using-eye-gaze-as-a-primary-input-pointer"></a>プライマリ入力ポインターとして視線を使用するアプリのフォールバック
アプリがポインター入力として視線を使用してシーン全体のホログラムをすばやく選択していても、目の追跡データが使用できない場合は、頭を見つめて、頭を見つめたカーソルを表示し始めることをお勧めします。 切り替えるかどうかを判断するには、タイムアウト (500 ~ 1500 ミリ秒など) を使用することをお勧めします。 この操作により、システムが短時間の動きやウインクによって追跡が一時的に失われるたびにカーソルが表示されないようにすることができます。 Unity 開発者の場合、ヘッドの自動フォールバックは、Mixed Reality Toolkit で既に処理されています。 DirectX 開発者は、このスイッチを自分で処理する必要があります。

### <a name="fallback-for-other-eye-tracking-specific-applications"></a>その他の視点を特定するアプリケーションのフォールバック
アプリは、目を絞って特別に調整された独自の方法で、目を見つめて使用する場合があります。 たとえば、アバターの目をアニメーション化したり、目をヒートマップに注目したりするには、視覚的な注意に関する正確な情報に依存します。 この場合、明確なフォールバックはありません。 視線追跡が使用できない場合は、これらの機能を無効にする必要がある場合があります。
ここでも、機能が動作していないことを認識していない可能性のあるユーザーに、このことを明確に伝えることをお勧めします。

<br>

このページでは、HoloLens 2 の視線追跡と視線入力の役割を理解するのに役立つ概要が提供されています。 開発を開始するには、ホログラムとの [相互作用のための視線](eye-gaze-interaction.md)の役割についての情報を確認します。また、 [Unity で](https://aka.ms/mrtk-eyes) は目を見つめ、 [DirectX で](../develop/native/gaze-in-directx.md)は目を見つめます。


## <a name="see-also"></a>関連項目
* [調整](../calibration.md)
* [快適性](comfort.md)
* [目の視線入力ベースの操作](eye-gaze-interaction.md)
* [DirectX での視線](../develop/native/gaze-in-directx.md)
* [Unity での視線 (Mixed Reality Toolkit)](https://aka.ms/mrtk-eyes)
* [視線入力とコミット](gaze-and-commit.md)
* [音声入力](../out-of-scope/voice-design.md)


