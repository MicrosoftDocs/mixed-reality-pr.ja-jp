---
title: 目の視線入力とコミット
description: 目の視線入力とコミットの入力モデルについて説明します。
author: sostel
ms.author: sostel
ms.date: 05/05/2019
ms.topic: article
ms.localizationpriority: high
keywords: 視線追跡, Mixed Reality, 入力, 目の視線入力, 目のターゲット設定, HoloLens 2, 視線に基づく選択, Mixed Reality ヘッドセット, Windows Mixed Reality ヘッドセット, 仮想現実ヘッドセット, HoloLens, MRTK, Mixed Reality Toolkit, 視線入力
ms.openlocfilehash: 1f337d3cbc1f82b4f69194d4b903687be067f9d6
ms.sourcegitcommit: d340303cda71c31e6c3320231473d623c0930d33
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 01/01/2021
ms.locfileid: "97847871"
---
# <a name="eye-gaze-and-commit"></a><span data-ttu-id="38bed-104">目の視線入力とコミット</span><span class="sxs-lookup"><span data-stu-id="38bed-104">Eye-gaze and commit</span></span>

<span data-ttu-id="38bed-105">_目の視線入力とコミット_ は、オブジェクトを見ることによってターゲットにすることが含まれる、[視線入力とコミット](gaze-and-commit.md)入力モデルの特殊なケースです。</span><span class="sxs-lookup"><span data-stu-id="38bed-105">_Eye-gaze and commit_ is a special [gaze and commit](gaze-and-commit.md) input model case that involves targeting an object by looking at it.</span></span> <span data-ttu-id="38bed-106">ユーザーは、手のジェスチャ、音声コマンド、ゲーム コントローラーのような周辺入力機器など、セカンダリ "_コミット_" 入力を使用してそのターゲットを操作できます。</span><span class="sxs-lookup"><span data-stu-id="38bed-106">You can act on the target with a secondary _commit_ input, such as a hand gesture, voice command, or peripheral input like a game controller.</span></span> 

<span data-ttu-id="38bed-107">HoloLens 2 では、頭の視線入力ではなく目の視線入力を使用することで _視線入力とコミット_ をより迅速で快適なものにできます。</span><span class="sxs-lookup"><span data-stu-id="38bed-107">With HoloLens 2, we have the great opportunity to make _gaze and commit_ faster and more comfortable by using eye-gaze instead of head-gaze.</span></span> <span data-ttu-id="38bed-108">一般的な[頭の視線入力とコミット](gaze-and-commit.md)の相互作用モデルを拡張するには:</span><span class="sxs-lookup"><span data-stu-id="38bed-108">To extend the common [head-gaze and commit](gaze-and-commit.md) interaction model:</span></span> 
1. <span data-ttu-id="38bed-109">ターゲットを見る。</span><span class="sxs-lookup"><span data-stu-id="38bed-109">Look at a target</span></span> 
2. <span data-ttu-id="38bed-110">次のような明示的セカンダリ入力を使用して、そのターゲットを選択するという意図を確認する。</span><span class="sxs-lookup"><span data-stu-id="38bed-110">To confirm your intention to select the target, use a secondary explicit input such as a:</span></span>  
   - <span data-ttu-id="38bed-111">手のジェスチャ (エアタップなど)</span><span class="sxs-lookup"><span data-stu-id="38bed-111">Hand gesture (for example, an Air Tap)</span></span>
   - <span data-ttu-id="38bed-112">ボタン押下 (Bluetooth キーボードやクリッカーなど)</span><span class="sxs-lookup"><span data-stu-id="38bed-112">Button press (for example, on a Bluetooth keyboard or clicker)</span></span>
   - <span data-ttu-id="38bed-113">音声コマンド ("選択" など)</span><span class="sxs-lookup"><span data-stu-id="38bed-113">Voice command (for example, "Select")</span></span>
   - <span data-ttu-id="38bed-114">ドウェル (ユーザーがターゲットを見つめ続けて選択する方法)</span><span class="sxs-lookup"><span data-stu-id="38bed-114">Dwelling (that is, the user simply keeps looking at the target to select)</span></span>

<span data-ttu-id="38bed-115">ただし、目の視線入力はいくつかの点で頭の視線入力と動作が異なっており、さまざまな固有の課題があります。</span><span class="sxs-lookup"><span data-stu-id="38bed-115">However, eye gaze behaves differently to head gaze in certain ways and comes with many unique challenges.</span></span> <span data-ttu-id="38bed-116">ホログラフィック アプリで視線追跡を入力として使用する場合の一般的なメリットと課題の概要については、[目の視線入力の設計ガイドライン](eye-tracking.md)に関するページを参照してください。</span><span class="sxs-lookup"><span data-stu-id="38bed-116">In the [Eye Gaze Design Guidelines](eye-tracking.md), we summarize general advantages and challenges when using eye tracking as an input in your holographic app.</span></span> <span data-ttu-id="38bed-117">このセクションでは、_目の視線入力とコミット_ に関する特定の設計考慮事項を中心に説明します。</span><span class="sxs-lookup"><span data-stu-id="38bed-117">In this section, we focus on the specific design considerations for _eye-gaze and commit_.</span></span>
<span data-ttu-id="38bed-118">まず、目は非常に速く動かせるので、視界からすばやくターゲット設定を行うのに適しています。</span><span class="sxs-lookup"><span data-stu-id="38bed-118">First, our eyes move incredibly fast and are great at quickly targeting across the view.</span></span> <span data-ttu-id="38bed-119">目の視線入力は、特に、エアタップやボタン押下などの高速コミットと組み合わせると、視線入力とコミットをすばやく行うのに最適です。</span><span class="sxs-lookup"><span data-stu-id="38bed-119">Eye-gaze is ideal for quick gaze-and-commit actions especially when combined with fast commits such as an air tap or button press.</span></span>
   
## <a name="design-guidelines-for-eye-gaze-and-commit"></a><span data-ttu-id="38bed-120">目の視線入力とコミットに関する設計ガイドライン</span><span class="sxs-lookup"><span data-stu-id="38bed-120">Design guidelines for eye-gaze and commit</span></span>

<span data-ttu-id="38bed-121">**カーソルを表示しない**:頭の視線入力を使用する場合、カーソルを使わずに操作するのはほぼ不可能ですが、目の視線入力を使用する場合は、カーソルが表示されると気が散って目障りに感じられます。</span><span class="sxs-lookup"><span data-stu-id="38bed-121">**Don't show a cursor**: While it's nearly impossible to interact without a cursor when using head gaze, the cursor becomes quickly distracting and annoying when using eye gaze.</span></span> <span data-ttu-id="38bed-122">視線追跡が機能しているかどうかや、現在見ているターゲットを正しく検出したかどうかをユーザーに知らせるには、カーソルに頼るのではなく、繊細なビジュアル ハイライトを使用します。</span><span class="sxs-lookup"><span data-stu-id="38bed-122">Instead of relying on a cursor to inform the user whether eye tracking is working and has correctly detected the currently looked at target, use subtle visual highlights.</span></span>

<span data-ttu-id="38bed-123">**繊細なブレンド ホバー フィードバックを追求する**:頭の視線入力にとっては優れた視覚的フィードバックが、目の視線入力にとっては不快で混乱するエクスペリエンスになる可能性があります。</span><span class="sxs-lookup"><span data-stu-id="38bed-123">**Strive for subtle blended hover feedback**: What seems great visual feedback for head gaze can result in terrible, overwhelming experiences using eye gaze.</span></span> <span data-ttu-id="38bed-124">目の動きは非常に速いため、視野の中の点から点へとすばやく動くことにご注意ください。</span><span class="sxs-lookup"><span data-stu-id="38bed-124">Remember, your eyes are enormously fast, quickly darting across points in your field-of-view.</span></span> <span data-ttu-id="38bed-125">周りを見回しているときに急にハイライトが変化 (オン/オフ) すると、フィードバックがちらつく可能性があります。</span><span class="sxs-lookup"><span data-stu-id="38bed-125">Quick sudden highlight changes (on/off) may result in flickery feedback when looking around.</span></span> <span data-ttu-id="38bed-126">そのため、ホバー フィードバックを提供する場合は、スムーズ ブレンドイン ハイライト (視線を外す場合はスムーズ ブレンドアウト ハイライト) を使用することをお勧めします。</span><span class="sxs-lookup"><span data-stu-id="38bed-126">So, when providing hover feedback, we recommend using a smoothly blended-in highlight (and blended-out when looking away).</span></span> <span data-ttu-id="38bed-127">このようにすると、ターゲットを見たときに、最初はフィードバックにほとんど気付きません。</span><span class="sxs-lookup"><span data-stu-id="38bed-127">This means at first you would barely notice the feedback when looking at a target.</span></span> <span data-ttu-id="38bed-128">500 - 1000 ミリ秒かけて、ハイライトの輝度が上がります。</span><span class="sxs-lookup"><span data-stu-id="38bed-128">Over the course of 500-1000 ms the highlight would increase in intensity.</span></span> <span data-ttu-id="38bed-129">初級ユーザーは見つめているターゲットが正しく判別されたことを確かめようとしてターゲットを見つめ続けるかもしれませんが、上級ユーザーはフィードバックが最大輝度になるのを待たずにすばやく視線入力とコミットを実行できます。</span><span class="sxs-lookup"><span data-stu-id="38bed-129">While novice users could keep looking at the target to ensure the system has correctly determined the focused target, expert users could quickly gaze-and-commit without waiting until the feedback is at its full intensity.</span></span> <span data-ttu-id="38bed-130">また、ホバー フィードバックをフェードアウトするときにブレンドアウトを使用することもお勧めします。</span><span class="sxs-lookup"><span data-stu-id="38bed-130">We also recommend using a blend-out when fading out the hover feedback.</span></span> <span data-ttu-id="38bed-131">調査により、周辺視野 (自分が注視していない視野領域) では動きやコントラストの急激な変化に気付きやすいことがわかっています。</span><span class="sxs-lookup"><span data-stu-id="38bed-131">Research has shown that quick motions and contrast changes are noticeable in your peripheral vision (the area of your visual field where you aren't looking).</span></span>
<span data-ttu-id="38bed-132">フェードアウトをブレンドインと同じほど遅くする必要はありません。</span><span class="sxs-lookup"><span data-stu-id="38bed-132">The fade-out doesn't have to be as slow as the blend-in.</span></span> <span data-ttu-id="38bed-133">このことは、ハイライトのコントラストが高い場合や色が変化する場合にのみ重要です。</span><span class="sxs-lookup"><span data-stu-id="38bed-133">This is only critical when you have high contrast or color changes for your highlight.</span></span> <span data-ttu-id="38bed-134">最初のうちホバー フィードバックが繊細な場合、違いに気付かないかもしれません。</span><span class="sxs-lookup"><span data-stu-id="38bed-134">If the hover feedback was subtle to begin with, you probably won't notice a difference.</span></span>

<span data-ttu-id="38bed-135">**視線入力とコミット信号を同期させるよう配慮する**:入力信号の同期は、単純なエア タップやボタン押下の場合は大きな問題ではありません。</span><span class="sxs-lookup"><span data-stu-id="38bed-135">**Look out for synchronizing gaze and commit signals**: The synchronization of input signals may be less of a challenge for simple air taps and button presses.</span></span> <span data-ttu-id="38bed-136">長い音声コマンドや複雑な手のジェスチャが必要になる可能性のある、より複雑なコミット アクションを使用する場合は注意が必要です。</span><span class="sxs-lookup"><span data-stu-id="38bed-136">It's something to look out for in case you want to use more complicated commit actions that may involve long voice commands or complicated hand gestures.</span></span> <span data-ttu-id="38bed-137">ターゲットを見つめて、長い音声コマンドを発音する場合を想像してください。</span><span class="sxs-lookup"><span data-stu-id="38bed-137">Imagine you look at a target and utter a long voice command.</span></span> <span data-ttu-id="38bed-138">発音に必要な時間と、発音された内容をシステムが検出するのに必要な時間を考えると、目の視線入力はシーン内の離れた場所にある新しいターゲットに移動している可能性があります。</span><span class="sxs-lookup"><span data-stu-id="38bed-138">Think about the time you need to say it and the time that the system needed to detect what you said, your eye gaze has long moved on to some new target in the scene.</span></span> <span data-ttu-id="38bed-139">そのため、コマンドが認識されるまでターゲットを見つめ続けなければならないことをユーザーに気付かせるか、コマンドの開始とユーザーがその時点で見ていたものを特定するという方法で入力を処理する必要があります。</span><span class="sxs-lookup"><span data-stu-id="38bed-139">Either make your users aware they may need to keep looking at a target until the command has been recognized or handle the input in a way to determine the onset of the command and what the user had been looking at back then.</span></span>

## <a name="see-also"></a><span data-ttu-id="38bed-140">関連項目</span><span class="sxs-lookup"><span data-stu-id="38bed-140">See also</span></span>

* <span data-ttu-id="38bed-141">[視線ベースの操作] (eye-gaze-interaction.md)</span><span class="sxs-lookup"><span data-stu-id="38bed-141">[Eye-based interaction] (eye-gaze-interaction.md)</span></span>
* <span data-ttu-id="38bed-142">[HoloLens 2 上の視線追跡] (eye-tracking.md)</span><span class="sxs-lookup"><span data-stu-id="38bed-142">[Eye tracking on HoloLens 2] (eye-tracking.md)</span></span>
* [<span data-ttu-id="38bed-143">視線入力とコミット</span><span class="sxs-lookup"><span data-stu-id="38bed-143">Gaze and commit</span></span>](gaze-and-commit.md)
* [<span data-ttu-id="38bed-144">視線入力とドウェル</span><span class="sxs-lookup"><span data-stu-id="38bed-144">Gaze and dwell</span></span>](gaze-and-dwell.md)
* [<span data-ttu-id="38bed-145">手 - 直接操作</span><span class="sxs-lookup"><span data-stu-id="38bed-145">Hands - Direct manipulation</span></span>](direct-manipulation.md)
* [<span data-ttu-id="38bed-146">手 - ジェスチャ</span><span class="sxs-lookup"><span data-stu-id="38bed-146">Hands - Gestures</span></span>](gaze-and-commit.md#composite-gestures)
* [<span data-ttu-id="38bed-147">手 - ポイントとコミット</span><span class="sxs-lookup"><span data-stu-id="38bed-147">Hands - Point and commit</span></span>](point-and-commit.md)
* [<span data-ttu-id="38bed-148">本能的な操作</span><span class="sxs-lookup"><span data-stu-id="38bed-148">Instinctual interactions</span></span>](interaction-fundamentals.md)
* [<span data-ttu-id="38bed-149">音声入力</span><span class="sxs-lookup"><span data-stu-id="38bed-149">Voice input</span></span>](voice-input.md)
