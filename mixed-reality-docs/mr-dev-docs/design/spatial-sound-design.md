---
title: 混合現実アプリケーションでの空間サウンドの使用
description: 空間サウンドは、mixed reality アプリケーションでの immersion、アクセシビリティ、UX の設計のための強力なツールです。
author: kegodin
ms.author: v-hferrone
ms.date: 11/02/2019
ms.topic: article
keywords: Windows Mixed Reality、空間サウンド、設計、スタイル、mixed reality ヘッドセット、windows mixed reality ヘッドセット、virtual reality ヘッドセット、HoloLens、MRTK、Mixed Reality Toolkit、ジェスチャ、相互作用、減衰
ms.openlocfilehash: fe77d62bcdfc67579deee619fc7f4949676aaed6
ms.sourcegitcommit: d340303cda71c31e6c3320231473d623c0930d33
ms.translationtype: MT
ms.contentlocale: ja-JP
ms.lasthandoff: 01/01/2021
ms.locfileid: "97848177"
---
# <a name="how-to-use-sound-in-mixed-reality-applications"></a><span data-ttu-id="deff7-104">Mixed reality アプリケーションでサウンドを使用する方法</span><span class="sxs-lookup"><span data-stu-id="deff7-104">How to use sound in mixed-reality applications</span></span>

<span data-ttu-id="deff7-105">サウンドを使用して、ユーザーのアプリケーション状態のメンタルモデルを通知し、補強することができます。</span><span class="sxs-lookup"><span data-stu-id="deff7-105">You can use sound to inform and reinforce the user's mental model of application state.</span></span> <span data-ttu-id="deff7-106">必要に応じて spatialization を使用して、mixed reality の世界にサウンドを配置します。</span><span class="sxs-lookup"><span data-stu-id="deff7-106">Use spatialization, when appropriate, to place sounds in the mixed-reality world.</span></span> <span data-ttu-id="deff7-107">この方法で聴覚とビジュアルを接続すると、相互作用の直感的な性質が高まり、ユーザーの信頼度が向上します。</span><span class="sxs-lookup"><span data-stu-id="deff7-107">When you connect the auditory and the visual in this way, you deepen the intuitive nature of interactions and increase user confidence.</span></span>
<br><br>

<iframe width="940" height="530" src="https://www.youtube.com/embed/aB3TDjYklmo" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

## <a name="when-to-add-sounds"></a><span data-ttu-id="deff7-108">サウンドを追加するタイミング</span><span class="sxs-lookup"><span data-stu-id="deff7-108">When to add sounds</span></span>

<span data-ttu-id="deff7-109">混合現実のアプリケーションでは、tactile インターフェイスがないため、多くの場合、2D アプリよりもサウンドが必要になります。</span><span class="sxs-lookup"><span data-stu-id="deff7-109">Mixed-reality applications often have a greater need for sound than 2D apps, because of their lack of a tactile interface.</span></span> <span data-ttu-id="deff7-110">ユーザーに通知したり、対話を補強したりするときに、サウンドを追加します。</span><span class="sxs-lookup"><span data-stu-id="deff7-110">Add sounds when they inform the user or reinforce interactions.</span></span>

### <a name="inform-and-reinforce"></a><span data-ttu-id="deff7-111">通知と補強</span><span class="sxs-lookup"><span data-stu-id="deff7-111">Inform and reinforce</span></span>

* <span data-ttu-id="deff7-112">通知など、ユーザーによって開始されていないイベントについては、音を使用して、変更が発生したことをユーザーに通知します。</span><span class="sxs-lookup"><span data-stu-id="deff7-112">For events that aren't initiated by the user, such as notifications, use sound to inform the user that a change occurred.</span></span>
* <span data-ttu-id="deff7-113">相互作用には複数の段階があります。</span><span class="sxs-lookup"><span data-stu-id="deff7-113">Interactions may have several stages.</span></span> <span data-ttu-id="deff7-114">音を使用してステージの遷移を補強します。</span><span class="sxs-lookup"><span data-stu-id="deff7-114">Use sound to reinforce stage transitions.</span></span>

<span data-ttu-id="deff7-115">相互作用、イベント、および推奨されるサウンド特性の次の例を参照してください。</span><span class="sxs-lookup"><span data-stu-id="deff7-115">See the following examples of interactions, events, and suggested sound characteristics.</span></span>

### <a name="exercise-restraint"></a><span data-ttu-id="deff7-116">演習ガイド</span><span class="sxs-lookup"><span data-stu-id="deff7-116">Exercise restraint</span></span>

<span data-ttu-id="deff7-117">オーディオ情報の容量に制限はありません。</span><span class="sxs-lookup"><span data-stu-id="deff7-117">Users don't have an unlimited capacity for audio information.</span></span>
* <span data-ttu-id="deff7-118">各サウンドは、特定の重要な情報を伝達します。</span><span class="sxs-lookup"><span data-stu-id="deff7-118">Each sound should communicate specific, valuable information.</span></span>
* <span data-ttu-id="deff7-119">アプリがサウンドを再生してユーザーに通知するときに、他のサウンドの音量を一時的に下げます。</span><span class="sxs-lookup"><span data-stu-id="deff7-119">When your app plays a sound to inform the user, temporarily reduce the volume of other sounds.</span></span>
* <span data-ttu-id="deff7-120">ボタンをポイントしたときのサウンド (次の情報を参照) については、待ち時間を追加して、音が過剰にトリガーされないようにします。</span><span class="sxs-lookup"><span data-stu-id="deff7-120">For button hover sounds (see the following information), add a time delay to prevent excessive sound triggering.</span></span>

### <a name="dont-rely-solely-on-sounds"></a><span data-ttu-id="deff7-121">サウンドだけに依存しない</span><span class="sxs-lookup"><span data-stu-id="deff7-121">Don't rely solely on sounds</span></span>

<span data-ttu-id="deff7-122">よく使用されるサウンドは、ユーザーにとって価値があります。</span><span class="sxs-lookup"><span data-stu-id="deff7-122">Sounds that are used well are valuable to your users.</span></span> <span data-ttu-id="deff7-123">ただし、サウンドがオフになっている場合でもアプリケーションが使用可能であることを確認してください。</span><span class="sxs-lookup"><span data-stu-id="deff7-123">But make sure your application is usable even with the sound turned off.</span></span>
* <span data-ttu-id="deff7-124">ユーザーの聴覚が不自由になっている可能性があります。</span><span class="sxs-lookup"><span data-stu-id="deff7-124">Users may be hearing impaired.</span></span>
* <span data-ttu-id="deff7-125">アプリケーションは、大いな環境で使用できます。</span><span class="sxs-lookup"><span data-stu-id="deff7-125">Your application may be used in a loud environment.</span></span>
* <span data-ttu-id="deff7-126">ユーザーには、プライバシーに関する考慮事項や、デバイスオーディオを無効にするその他の理由が考えられます。</span><span class="sxs-lookup"><span data-stu-id="deff7-126">Users may have privacy concerns or other reasons to disable device audio.</span></span>

## <a name="how-to-sonify-interactions"></a><span data-ttu-id="deff7-127">相互作用を sonify する方法</span><span class="sxs-lookup"><span data-stu-id="deff7-127">How to sonify interactions</span></span>

<span data-ttu-id="deff7-128">混合現実の対話型には、ジェスチャ、直接操作、音声などがあります。</span><span class="sxs-lookup"><span data-stu-id="deff7-128">Interaction types in mixed reality include gesture, direct manipulation, and voice.</span></span> <span data-ttu-id="deff7-129">次の推奨される特性を使用して、これらのインタラクションのサウンドを選択または設計します。</span><span class="sxs-lookup"><span data-stu-id="deff7-129">Use the following suggested characteristics to select or design sounds for these interactions.</span></span>

### <a name="gesture-interactions"></a><span data-ttu-id="deff7-130">ジェスチャの相互作用</span><span class="sxs-lookup"><span data-stu-id="deff7-130">Gesture interactions</span></span>

<span data-ttu-id="deff7-131">Mixed reality では、ユーザーはマウスを使用してボタンを操作できます。</span><span class="sxs-lookup"><span data-stu-id="deff7-131">In mixed reality, users may interact with buttons by using a mouse.</span></span> <span data-ttu-id="deff7-132">ボタンの操作は、通常、ユーザーがボタンをクリックするのではなく、ユーザーが操作をキャンセルできるようにしたときに発生します。</span><span class="sxs-lookup"><span data-stu-id="deff7-132">Button actions generally occur when the user releases rather than presses the button to give the user a chance to cancel the interaction.</span></span> <span data-ttu-id="deff7-133">サウンドを使用して、これらのステージを補強します。</span><span class="sxs-lookup"><span data-stu-id="deff7-133">Use sounds to reinforce these stages.</span></span> <span data-ttu-id="deff7-134">離れた場所にあるボタンをユーザーがターゲットとして使用できるようにするには、ポインターをポイントするサウンドの使用も検討してください。</span><span class="sxs-lookup"><span data-stu-id="deff7-134">To assist users in targeting distant buttons, also consider using a pointer-hover sound.</span></span>
* <span data-ttu-id="deff7-135">ボタン-enter キーを押すと、tactile の "クリック" が短くなります。</span><span class="sxs-lookup"><span data-stu-id="deff7-135">Button-press sounds should be a short, tactile "click."</span></span><br/><span data-ttu-id="deff7-136">例: [MRTK_ButtonPress .wav](https://github.com/microsoft/MixedRealityToolkit-Unity/tree/mrtk_development/Assets/MRTK/SDK/StandardAssets/Audio/MRTK_ButtonPress.wav)</span><span class="sxs-lookup"><span data-stu-id="deff7-136">Example: [MRTK_ButtonPress.wav](https://github.com/microsoft/MixedRealityToolkit-Unity/tree/mrtk_development/Assets/MRTK/SDK/StandardAssets/Audio/MRTK_ButtonPress.wav)</span></span>
* <span data-ttu-id="deff7-137">ボタン-"押されていない" サウンドは、同様の tactile 感を持つ必要があります。</span><span class="sxs-lookup"><span data-stu-id="deff7-137">Button-"unpress" sounds should have a similar tactile feel.</span></span> <span data-ttu-id="deff7-138">押されたサウンドよりも高いピッチで、完了の意味がわかります。</span><span class="sxs-lookup"><span data-stu-id="deff7-138">A higher pitch than the press sound reinforces the sense of completion.</span></span><br/><span data-ttu-id="deff7-139">例: [MRTK_ButtonUnpress .wav](https://github.com/microsoft/MixedRealityToolkit-Unity/tree/mrtk_development/Assets/MRTK/SDK/StandardAssets/Audio/MRTK_ButtonUnpress.wav)</span><span class="sxs-lookup"><span data-stu-id="deff7-139">Example: [MRTK_ButtonUnpress.wav](https://github.com/microsoft/MixedRealityToolkit-Unity/tree/mrtk_development/Assets/MRTK/SDK/StandardAssets/Audio/MRTK_ButtonUnpress.wav)</span></span>
* <span data-ttu-id="deff7-140">ホバーサウンドの場合は、低周波数の thud やバンプなど、微妙で脅威のないサウンドを使用することを検討してください。</span><span class="sxs-lookup"><span data-stu-id="deff7-140">For hover sounds, consider using a subtle and non-threatening sound, such as a low-frequency thud or bump.</span></span>

### <a name="direct-manipulation"></a><span data-ttu-id="deff7-141">直接操作</span><span class="sxs-lookup"><span data-stu-id="deff7-141">Direct manipulation</span></span>

<span data-ttu-id="deff7-142">HoloLens 2 では、独自の追跡はユーザーインターフェイス要素の直接操作をサポートしています。</span><span class="sxs-lookup"><span data-stu-id="deff7-142">On HoloLens 2, articulated hand tracking supports direct manipulation of user-interface elements.</span></span> <span data-ttu-id="deff7-143">他の物理的なフィードバックがない場合は、音が重要になります。</span><span class="sxs-lookup"><span data-stu-id="deff7-143">Sounds are important when there's no other physical feedback.</span></span>

<span data-ttu-id="deff7-144">キーストロークの一番下に到達したときにユーザーが何も表示しないため、 *ボタンを押す* 音が重要になります。</span><span class="sxs-lookup"><span data-stu-id="deff7-144">A *button press* sound is important because the user doesn't get any other indication when they reach the bottom of the key stroke.</span></span> <span data-ttu-id="deff7-145">キー移動のサウンドインジケーターは、小、軽度、occluded にすることができます。</span><span class="sxs-lookup"><span data-stu-id="deff7-145">Sound indicators of key travel can be small, subtle, and occluded.</span></span> <span data-ttu-id="deff7-146">ジェスチャの対話と同様に、ボタンを押すと、クリックのような短い tactile サウンドが表示されます。</span><span class="sxs-lookup"><span data-stu-id="deff7-146">As with gesture interactions, button presses should get a short, tactile sound like a click.</span></span> <span data-ttu-id="deff7-147">Unpresses は、同じようなクリック音を持つ必要がありますが、ピッチが発生します。</span><span class="sxs-lookup"><span data-stu-id="deff7-147">Unpresses should have a similar click sound but with raised pitch.</span></span>
* <span data-ttu-id="deff7-148">例: [MRTK_ButtonPress .wav](https://github.com/microsoft/MixedRealityToolkit-Unity/tree/mrtk_development/Assets/MRTK/SDK/StandardAssets/Audio/MRTK_ButtonPress.wav)</span><span class="sxs-lookup"><span data-stu-id="deff7-148">Example: [MRTK_ButtonPress.wav](https://github.com/microsoft/MixedRealityToolkit-Unity/tree/mrtk_development/Assets/MRTK/SDK/StandardAssets/Audio/MRTK_ButtonPress.wav)</span></span>
* <span data-ttu-id="deff7-149">例: [MRTK_ButtonUnpress .wav](https://github.com/microsoft/MixedRealityToolkit-Unity/tree/mrtk_development/Assets/MRTK/SDK/StandardAssets/Audio/MRTK_ButtonUnpress.wav)</span><span class="sxs-lookup"><span data-stu-id="deff7-149">Example: [MRTK_ButtonUnpress.wav](https://github.com/microsoft/MixedRealityToolkit-Unity/tree/mrtk_development/Assets/MRTK/SDK/StandardAssets/Audio/MRTK_ButtonUnpress.wav)</span></span>

<span data-ttu-id="deff7-150">グラブまたはリリースアクションを視覚的に確認することは困難です。</span><span class="sxs-lookup"><span data-stu-id="deff7-150">It's difficult to visually confirm a grab or release action.</span></span> <span data-ttu-id="deff7-151">多くの場合、ユーザーの手は視覚的な効果を持つようになります。また、ハードハンドのオブジェクトには、"グラブ" という実際の視覚アナログがありません。</span><span class="sxs-lookup"><span data-stu-id="deff7-151">The user's hand will often be in the way of any visual effect, and hard-bodied objects lack a real-world visual analog of "grabbing."</span></span> <span data-ttu-id="deff7-152">サウンドは、成功したグラブとリリースの相互作用を効果的に伝えることができます。</span><span class="sxs-lookup"><span data-stu-id="deff7-152">Sounds can effectively communicate successful grab and release interactions.</span></span>
* <span data-ttu-id="deff7-153">グラブアクションには、オブジェクトの周りを閉じるように求めるための短い muffled tactile サウンドが必要です。</span><span class="sxs-lookup"><span data-stu-id="deff7-153">Grab actions should have a short, somewhat-muffled tactile sound that prompts the idea of fingers closing around an object.</span></span> <span data-ttu-id="deff7-154">また、"whoosh" 音が発生して、手の動きを知らせる音が出てくることもあります。</span><span class="sxs-lookup"><span data-stu-id="deff7-154">Sometimes there's also a "whoosh" sound that leads up to the grabbing sound to communicate the motion of the hand.</span></span><br/><span data-ttu-id="deff7-155">例: [MRTK_Move_Start .wav](https://github.com/microsoft/MixedRealityToolkit-Unity/tree/mrtk_development/Assets/MRTK/SDK/StandardAssets/Audio/MRTK_Move_Start.wav)</span><span class="sxs-lookup"><span data-stu-id="deff7-155">Example: [MRTK_Move_Start.wav](https://github.com/microsoft/MixedRealityToolkit-Unity/tree/mrtk_development/Assets/MRTK/SDK/StandardAssets/Audio/MRTK_Move_Start.wav)</span></span>
* <span data-ttu-id="deff7-156">リリースアクションは、同様の短いサウンドと tactile サウンドを取得する必要があります。</span><span class="sxs-lookup"><span data-stu-id="deff7-156">Release actions should get a similarly short and tactile sound.</span></span> <span data-ttu-id="deff7-157">通常は、グラブ音と逆の順序で、オブジェクトが所定の位置にあることを通知する "whoosh" に影響を与えます。</span><span class="sxs-lookup"><span data-stu-id="deff7-157">It's usually lower pitched than the grab sound and in reverse order, with an impact and then a "whoosh" to communicate that the object is settling into place.</span></span><br/><span data-ttu-id="deff7-158">例: [MRTK_Move_End .wav](https://github.com/microsoft/MixedRealityToolkit-Unity/tree/mrtk_development/Assets/MRTK/SDK/StandardAssets/Audio/MRTK_Move_End.wav)</span><span class="sxs-lookup"><span data-stu-id="deff7-158">Example: [MRTK_Move_End.wav](https://github.com/microsoft/MixedRealityToolkit-Unity/tree/mrtk_development/Assets/MRTK/SDK/StandardAssets/Audio/MRTK_Move_End.wav)</span></span>

<span data-ttu-id="deff7-159">*描画* の相互作用は、ユーザーの手の動きによって決定された音量を持つ、固定のループサウンドを取得する必要があります。</span><span class="sxs-lookup"><span data-stu-id="deff7-159">A *drawing* interaction should get a persistent, looping sound with volume determined by the user's hand movement.</span></span> <span data-ttu-id="deff7-160">ユーザーの手が、すぐに手を移動するときには、静かである必要があります。</span><span class="sxs-lookup"><span data-stu-id="deff7-160">It should be silent when the user's hand is still and loudest when the hand is moving quickly.</span></span>

### <a name="voice-interactions"></a><span data-ttu-id="deff7-161">音声操作</span><span class="sxs-lookup"><span data-stu-id="deff7-161">Voice interactions</span></span>

<span data-ttu-id="deff7-162">音声のやり取りには、微妙な視覚要素があることがよくあります。</span><span class="sxs-lookup"><span data-stu-id="deff7-162">Voice interactions often have subtle visual elements.</span></span> <span data-ttu-id="deff7-163">音を使用して、対話段階を補強します。</span><span class="sxs-lookup"><span data-stu-id="deff7-163">Use sounds to reinforce interaction stages.</span></span> <span data-ttu-id="deff7-164">より多くの色調音を使用して、ジェスチャや直接操作サウンドと区別することができます。</span><span class="sxs-lookup"><span data-stu-id="deff7-164">You may want to use more-tonal sounds to distinguish them from gesture and direct-manipulation sounds.</span></span>

* <span data-ttu-id="deff7-165">音声コマンドの確認には、正の音を *使用します*。</span><span class="sxs-lookup"><span data-stu-id="deff7-165">Use a positive-sounding tone for voice command *confirmations*.</span></span> <span data-ttu-id="deff7-166">増加している色調と主な音楽の間隔は効果的です。</span><span class="sxs-lookup"><span data-stu-id="deff7-166">Rising tones and major musical intervals are effective.</span></span>
* <span data-ttu-id="deff7-167">音声コマンドの *エラー* には、より短い、正の音で聞こえない音を使用します。</span><span class="sxs-lookup"><span data-stu-id="deff7-167">Use a shorter, less-positive-sounding tone for voice command *failures*.</span></span> <span data-ttu-id="deff7-168">負の音は避けてください。</span><span class="sxs-lookup"><span data-stu-id="deff7-168">Avoid negative sounds.</span></span> <span data-ttu-id="deff7-169">代わりに、percussive のニュートラルサウンドを使用して、アプリケーションが相互作用から移動していることを通知します。</span><span class="sxs-lookup"><span data-stu-id="deff7-169">Instead, use a more percussive, neutral sound to communicate that the application is moving on from the interaction.</span></span>
* <span data-ttu-id="deff7-170">アプリケーションにウェイクワードが含まれている場合は、デバイスが *リッスンを開始* するときに、短時間で緩やかに使用します。</span><span class="sxs-lookup"><span data-stu-id="deff7-170">If your application has a wake word, use a short, gentle tone when the device *starts listening*.</span></span> <span data-ttu-id="deff7-171">アプリケーション *が* リッスンしている間に、微妙なループサウンドを使用します。</span><span class="sxs-lookup"><span data-stu-id="deff7-171">Use  a subtle looping sound while the application *is* listening.</span></span>

### <a name="notifications"></a><span data-ttu-id="deff7-172">通知</span><span class="sxs-lookup"><span data-stu-id="deff7-172">Notifications</span></span>

<span data-ttu-id="deff7-173">通知は、アプリケーションの状態の変化や、ユーザーが開始しなかったその他のイベントを通知します。</span><span class="sxs-lookup"><span data-stu-id="deff7-173">Notifications signal application-state changes and other events the user didn't initiate.</span></span> <span data-ttu-id="deff7-174">状態の変更には、プロセスの完了、メッセージ、および電話の呼び出しを含めることができます。</span><span class="sxs-lookup"><span data-stu-id="deff7-174">State changes can include process completions, messages, and phone calls.</span></span>

<span data-ttu-id="deff7-175">Mixed reality では、オブジェクトがユーザーのビューのフィールドから移動する場合があります。</span><span class="sxs-lookup"><span data-stu-id="deff7-175">In mixed reality, objects sometimes move out of the user's field of view.</span></span> <span data-ttu-id="deff7-176">オブジェクトの種類と動き速度に依存する spatialized サウンドで、移動する *アニメーションオブジェクト* をペアにします。</span><span class="sxs-lookup"><span data-stu-id="deff7-176">Pair moving *animated objects* with a spatialized sound that depends on the object type and speed of motion.</span></span>
* <span data-ttu-id="deff7-177">これは、アニメーションの最後に spatialized サウンドを再生して、オブジェクトの新しい位置をユーザーに通知するのに役立ちます。</span><span class="sxs-lookup"><span data-stu-id="deff7-177">It helps to play a spatialized sound at the end of an animation to inform the user of the object's new position.</span></span>
* <span data-ttu-id="deff7-178">段階的な移動では、移動中の "whoosh" サウンドを使用して、ユーザーがオブジェクトを追跡できます。</span><span class="sxs-lookup"><span data-stu-id="deff7-178">For gradual movements, a "whoosh" sound during movement helps the user track the object.</span></span>

<span data-ttu-id="deff7-179">*メッセージ通知* 音は繰り返し発生する可能性があります。連続している場合もあります。</span><span class="sxs-lookup"><span data-stu-id="deff7-179">*Message notification* sounds may be heard repeatedly, sometimes in quick succession.</span></span> <span data-ttu-id="deff7-180">非常に重要なことです。</span><span class="sxs-lookup"><span data-stu-id="deff7-180">It's important they don't stand out or sound harsh.</span></span> <span data-ttu-id="deff7-181">中間範囲の正の色調音が有効になります。</span><span class="sxs-lookup"><span data-stu-id="deff7-181">Mid-range positive tonal sounds are effective.</span></span>

* <span data-ttu-id="deff7-182">着信音の音声は、携帯電話の着信音と同様の品質を持つ必要があります。</span><span class="sxs-lookup"><span data-stu-id="deff7-182">Incoming-call sounds should have similar qualities to a cell phone ringtone.</span></span> <span data-ttu-id="deff7-183">これらのサウンドは、ユーザーが通話に応答するまで再生されるミュージックフレーズをループします。</span><span class="sxs-lookup"><span data-stu-id="deff7-183">These sounds are looping musical phrases that play until the user answers the call.</span></span>
* <span data-ttu-id="deff7-184">音声通信の接続と切断には、短時間の色調音が必要です。</span><span class="sxs-lookup"><span data-stu-id="deff7-184">Voice communication connection and disconnection should have a short, tonal sound.</span></span> <span data-ttu-id="deff7-185">接続が成功したことを示すには、接続サウンドが正の音である必要があります。</span><span class="sxs-lookup"><span data-stu-id="deff7-185">The connection sound should be a positive tone to indicate a successful connection.</span></span> <span data-ttu-id="deff7-186">切断音は、呼び出しの完了を示すニュートラルサウンドである必要があります。</span><span class="sxs-lookup"><span data-stu-id="deff7-186">The disconnection sound should be a neutral sound to indicate completion of the call.</span></span>

## <a name="handle-spatialization"></a><span data-ttu-id="deff7-187">Spatialization の処理</span><span class="sxs-lookup"><span data-stu-id="deff7-187">Handle spatialization</span></span>

<span data-ttu-id="deff7-188">Spatialization は、ステレオヘッドホンまたはスピーカーを使用して、mixed reality の世界にサウンドを置きます。</span><span class="sxs-lookup"><span data-stu-id="deff7-188">Spatialization uses stereo headphones or speakers to place sounds in the mixed-reality world.</span></span>

### <a name="which-sounds-to-spatialize"></a><span data-ttu-id="deff7-189">Spatialize する音</span><span class="sxs-lookup"><span data-stu-id="deff7-189">Which sounds to spatialize</span></span>

<span data-ttu-id="deff7-190">空間位置を持つイベントに関連付けられている場合は、サウンドを spatialized する必要があります。</span><span class="sxs-lookup"><span data-stu-id="deff7-190">A sound should be spatialized when it's associated with an event that has a spatial location.</span></span> <span data-ttu-id="deff7-191">これには、UI、埋めを行う AI 音声、および視覚的インジケーターが含まれます。</span><span class="sxs-lookup"><span data-stu-id="deff7-191">This includes UI, embodied AI voices, and visual indicators.</span></span>

<span data-ttu-id="deff7-192">Spatialize *ユーザーインターフェイス* の要素を使用して、ユーザーの sonic "space" をまとめします。これは、ユーザーが聞く音声音の数を制限することによって行います。</span><span class="sxs-lookup"><span data-stu-id="deff7-192">Spatialize *user interface* elements to help declutter the user's sonic "space" by limiting the number of stereo sounds that they hear.</span></span> <span data-ttu-id="deff7-193">オーディオフィードバックが spatialized されると、タッチ、グラブ、解放などの操作の相互作用がより自然になります。</span><span class="sxs-lookup"><span data-stu-id="deff7-193">Manipulation interactions such as touching, grabbing, and releasing feel more natural when audio feedback is spatialized.</span></span> <span data-ttu-id="deff7-194">これらの要素の距離の減衰に関する次の情報を考慮してください。</span><span class="sxs-lookup"><span data-stu-id="deff7-194">Consider the following information about distance attenuation for these elements.</span></span>

<span data-ttu-id="deff7-195">*視覚インジケーター* *を Spatialize し、表示* されていないときにユーザーにわかりやすく表示します。</span><span class="sxs-lookup"><span data-stu-id="deff7-195">Spatialize *visual indicators* and *embodied AI voices* to intuitively inform users when these things are outside the field of view.</span></span>
    
<span data-ttu-id="deff7-196">これに対して、spatialization の *FACELESS AI 音声* や、空間位置が明確に定義されていないその他の要素については避けてください。</span><span class="sxs-lookup"><span data-stu-id="deff7-196">In contrast, avoid spatialization for *faceless AI voices* and other elements that lack a well-defined spatial location.</span></span> <span data-ttu-id="deff7-197">関連するビジュアル要素のない Spatialization は、ユーザーが見つけられない視覚的な要素があると考えることができないようにします。</span><span class="sxs-lookup"><span data-stu-id="deff7-197">Spatialization without a related visual element can distract users into thinking there's a visual element that they can't find.</span></span>

<span data-ttu-id="deff7-198">Spatialization には、いくつかの CPU コストが伴います。</span><span class="sxs-lookup"><span data-stu-id="deff7-198">Spatialization does come with some CPU cost.</span></span> <span data-ttu-id="deff7-199">多くのアプリケーションは同時に最大で2つのサウンドを再生しています。</span><span class="sxs-lookup"><span data-stu-id="deff7-199">Many applications have at most two sounds playing simultaneously.</span></span> <span data-ttu-id="deff7-200">この場合、spatialization のコストはごくわずかです。</span><span class="sxs-lookup"><span data-stu-id="deff7-200">The cost of spatialization in that case is likely negligible.</span></span> <span data-ttu-id="deff7-201">MRTK のフレームレートモニターを使用して、spatialization を追加した場合の影響を判断できます。</span><span class="sxs-lookup"><span data-stu-id="deff7-201">You can use the MRTK frame rate monitor to judge the impact of adding spatialization.</span></span>

### <a name="when-and-how-to-apply-distance-based-attenuation"></a><span data-ttu-id="deff7-202">距離ベースの減衰を適用するタイミングと方法</span><span class="sxs-lookup"><span data-stu-id="deff7-202">When and how to apply distance-based attenuation</span></span>

<span data-ttu-id="deff7-203">物理的な世界では、遠く離れている音はより静かです。</span><span class="sxs-lookup"><span data-stu-id="deff7-203">In the physical world, sounds that are farther away are quieter.</span></span> <span data-ttu-id="deff7-204">オーディオエンジンは、ソースの距離に基づいてこの減衰をモデル化できます。</span><span class="sxs-lookup"><span data-stu-id="deff7-204">Your audio engine can model this attenuation based on the source distance.</span></span> <span data-ttu-id="deff7-205">関連情報を通信するときは、距離ベースの減衰を使用します。</span><span class="sxs-lookup"><span data-stu-id="deff7-205">Use distance-based attenuation when it communicates relevant information.</span></span>

<span data-ttu-id="deff7-206">*視覚的なインジケーター*、アニメーション化された *ホログラム*、およびその他の情報音への距離は、ユーザーに関連します。</span><span class="sxs-lookup"><span data-stu-id="deff7-206">The distances to *visual indicators*, *animated holograms*, and other informative sounds are relevant to the user.</span></span> <span data-ttu-id="deff7-207">距離ベースの減衰を使用して、手掛かりを直感的に提供します。</span><span class="sxs-lookup"><span data-stu-id="deff7-207">Use distance-based attenuation to intuitively provide cues.</span></span>

<span data-ttu-id="deff7-208">各ソースの減衰曲線を、mixed reality ワールドの空間のサイズに合わせて調整します。</span><span class="sxs-lookup"><span data-stu-id="deff7-208">Adjust the attenuation curve for each source to fit the size of your mixed-reality world's spaces.</span></span> <span data-ttu-id="deff7-209">オーディオエンジンの既定の曲線は、多くの場合、大規模な (最大ハーフ kilometer の) スペースを想定しています。</span><span class="sxs-lookup"><span data-stu-id="deff7-209">Your audio engine's default curve is often meant for large (up to half-kilometer) spaces.</span></span>

<span data-ttu-id="deff7-210">ボタンアクションとその他の対話 *の段階的な段階* を補強する音は、減衰が適用されないようにします。</span><span class="sxs-lookup"><span data-stu-id="deff7-210">Sounds that reinforce the *progressive stages of button actions* and other interactions shouldn't get attenuation applied.</span></span> <span data-ttu-id="deff7-211">これらのサウンドの強化された効果は、ボタンへの距離を伝えるよりも重要です。</span><span class="sxs-lookup"><span data-stu-id="deff7-211">The reinforcing effects of these sounds are more important than communicating the distance to the button.</span></span> <span data-ttu-id="deff7-212">多くのボタンをクリックすると連続して表示される場合もありますが、特にキーボードでは混乱が生じる可能性があります。</span><span class="sxs-lookup"><span data-stu-id="deff7-212">Variations can be distracting, especially with keyboards, when many button clicks may be heard in succession.</span></span>

### <a name="which-spatialization-technology-to-use"></a><span data-ttu-id="deff7-213">使用する spatialization テクノロジ</span><span class="sxs-lookup"><span data-stu-id="deff7-213">Which spatialization technology to use</span></span>

<span data-ttu-id="deff7-214">ヘッドホンまたは HoloLens スピーカーでは、head 関連の転送関数 (HRTF) ベースの spatialization テクノロジを使用します。</span><span class="sxs-lookup"><span data-stu-id="deff7-214">With headphones or the HoloLens speakers, use head-related transfer function (HRTF)-based spatialization technologies.</span></span> <span data-ttu-id="deff7-215">これらのテクノロジは、物理的な世界でのヘッドの周りにおけるサウンド伝達をモデル化します。</span><span class="sxs-lookup"><span data-stu-id="deff7-215">These technologies model the sound propagation around the head in the physical world.</span></span> <span data-ttu-id="deff7-216">サウンドソースが1のヘッドの向こう側にある場合でも、サウンドは減衰と遅延によって遠くの耳に伝達されます。</span><span class="sxs-lookup"><span data-stu-id="deff7-216">Even when a sound source is on the far side of one's head, sound propagates to the distant ear with some attenuation and delay.</span></span> <span data-ttu-id="deff7-217">スピーカーパンは減衰にのみ依存し、サウンドが右側にあるときは左の耳に合計の減衰を適用し、もう1つの方法を適用します。</span><span class="sxs-lookup"><span data-stu-id="deff7-217">Speaker panning relies only on attenuation and applies total attenuation in the left ear when sounds are on the right side, and the other way around.</span></span> <span data-ttu-id="deff7-218">この手法は、"通常の聴覚" リスナーでは不快になる可能性があり、1つの耳で聴覚に障害があるリスナーではアクセスできません。</span><span class="sxs-lookup"><span data-stu-id="deff7-218">This technique can be uncomfortable for "normal hearing" listeners and inaccessible for listeners who have hearing impairment in one ear.</span></span>

## <a name="next-steps"></a><span data-ttu-id="deff7-219">次のステップ</span><span class="sxs-lookup"><span data-stu-id="deff7-219">Next steps</span></span>

* [<span data-ttu-id="deff7-220">Unity で空間サウンドを使用する</span><span class="sxs-lookup"><span data-stu-id="deff7-220">Use spatial sound in Unity</span></span>](../develop/unity/spatial-sound-in-unity.md)
* [<span data-ttu-id="deff7-221">Roboraid のケーススタディ</span><span class="sxs-lookup"><span data-stu-id="deff7-221">Case study of Roboraid</span></span>](case-study-using-spatial-sound-in-roboraid.md)
* [<span data-ttu-id="deff7-222">HoloTour のケーススタディ</span><span class="sxs-lookup"><span data-stu-id="deff7-222">Case study of HoloTour</span></span>](case-study-spatial-sound-design-for-holotour.md)
