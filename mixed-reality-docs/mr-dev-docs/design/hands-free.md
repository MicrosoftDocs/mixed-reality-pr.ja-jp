---
title: ハンズフリー
description: ユーザーが手とコントローラーのインターフェイスで直面する可能性がある問題と、さまざまな方法について説明します。
author: hferrone
ms.author: v-hferrone
ms.date: 04/20/2019
ms.topic: article
keywords: Mixed Reality、ハンズフリー、宝石、宝石をターゲット、相互作用、設計
ms.openlocfilehash: 47e2bd8fef52a36601d58f321def9c066db259e5
ms.sourcegitcommit: 09599b4034be825e4536eeb9566968afd021d5f3
ms.translationtype: MT
ms.contentlocale: ja-JP
ms.lasthandoff: 10/03/2020
ms.locfileid: "91686882"
---
# <a name="hands-free"></a>ハンズフリー

## <a name="scenarios"></a>シナリオ

「 [相互作用モデルの概要](interaction-fundamentals.md)」で説明されているように、ユーザーとその目的を特定したら、作業を遂行するために機能する際に直面する可能性がある環境や状況の課題を自分で確認します。 たとえば、多くのユーザーは、実際の目標を達成するためにユーザーを使用する必要があります。また、ユーザーには、ハンズオンベースのインターフェイスとの対話が困難になります。 

いくつかの具体的なシナリオとしては、次のものがあります。 
* ユーザーの手がふさがっているときにタスクを誘導する
* ユーザーの手がふさがっているときに資料を参照する
* 手の疲労
* 追跡できない手袋
* 手で何かを運んでいる
* 大きな手のジェスチャを実行するためのソーシャル awkwardness
* 狭いスペース


## <a name="hands-free-modalities"></a>ハンズフリーの感覚様相

### <a name="voice-input"></a>[音声入力](voice-input.md)

音声を使用してコマンドを実行し、インターフェイスを制御すると、必要に応じて複数の手順を柔軟にスキップするための便利な方法が提供されます。 音声入力を使用すると、ユーザーはボタンの名前を自由に読み取り、アクティブ化することができます _("参照してください" と言います)_ 。また、タスクを実行できるデジタルエージェントと会話します。


### <a name="gaze-and-dwell"></a>[視線入力とドウェル](gaze-and-dwell.md)

実際には、音声を使用するのは理想的ではなく、可能な場合もあります。 出荷時の環境、プライバシー、またはソーシャル規範はすべて制約となります。 ユーザーは、視線 + 熟考モデルを使用することにより、他の入力を必要とせずにアプリを移動することができます。ユーザーは、ターゲットで (ヘッドや目を使用して) 移動を維持して、アクティブ化するために lingers するだけです。 見つめ + 熟考の個々の設計上の考慮事項の詳細については、「 [視線 + 熟考](gaze-and-dwell-eyes.md) 」と「 [熟考](gaze-and-dwell-head.md)」をご覧ください。


## <a name="transitioning-in-and-out-of-hands-free"></a>ハンドフリーに移行する

これらのシナリオでは、コマンドの実行とナビゲーションのために、ホログラムを使用してハンドを解放する必要があります。これは、アプリケーションをエンドツーエンドで操作するための絶対的な要件であり、ユーザーがいつでも切り替えることができるようにするための追加の便宜です。 

アプリケーションの要件が常にハンズフリーで、熟考、カスタム音声コマンド、または単一の音声コマンドを使用しているかどうかにかかわらず、"select" を使用する場合は、必ず適切なものを UI に作成してください。 

対象ユーザーが自由に自由に切り替えられるようにする必要がある場合は、次の原則を考慮することが重要です。

### <a name="assume-the-user-is-already-in-the-mode-that-they-want-to-switch-to"></a>ユーザーが既に切り替え先のモードになっているとします。
たとえば、ユーザーが工場出荷時にビデオ参照を監視していて、ユーザーが自分の HoloLens でビデオ参照を見ていて、レンチを使用して作業を開始した場合、ほとんどの場合、ボタンを押すためにレンチを押す必要はありません。 彼女は、音声コマンドを使用して音声セッションを呼び出し、熟考を開始するために既に表示されている UI で熟考、"select" という単語を言い出すことができるはずです。

ユーザーは次のことを行うことができます。 
* ハンズフリーのまま、ハンドフリーに切り替える
* 手で手に切り替える
* コントローラーを使用してコントローラーに切り替える 

### <a name="create-redundant-ways-to-switch-modes"></a>モードを切り替えるための冗長な方法を作成する
最初の原則はアクセスに関するものですが、2番目の原則は可用性です。 モードを切り替える方法は1つだけではありません。 

次に例を示します。 
* 音声操作を開始するボタン
* ヘッド宝石と熟考を使用してに移行するための音声コマンド

### <a name="add-a-dash-of-drama"></a>ドラマのダッシュを追加する
モードの切り替えは非常に重要です。このような切り替えが行われたときに、ユーザーが何が起こったかをユーザーに知らせるために、これらの遷移が明示的であっても、劇的なスイッチであることが重要です。 


## <a name="usability-checklist"></a>使いやすさのチェックリスト

**エンドツーエンドであらゆることをユーザーが自由に実行できますか。**
* すべての対話型に自由にアクセスできます
* サイズ変更、配置、スワイプ、タップなどのすべてのカスタムジェスチャに代わるものがあることを確認します。
* UI のプレゼンス、配置、および詳細度を常にユーザーが確実に制御できるようにする
    * UI の取得方法
    * ビューの外にある UI のアドレス指定 (視界)
    * 表示する量 (

**相互作用のしくみは、適切な affordances を使用して学習し、補強するのでしょうか。**

ユーザーが理解している...
* ...どのモードであるか。
* ...このモードでできること
* ...現在の状態を確認できます。
* ...どのように移行できますか。
    
**UI はハンドフリーに最適化されていますか。**   

* 例: 熟考 affordances は、一般的な2D パターンに組み込まれていません。
* 例: オブジェクトの強調表示を使用すると、音声を対象にすることが適切です。
* 例: 音声通話は、有効にする必要があるキャプションに適しています。


## <a name="see-also"></a>関連項目
* [HoloLens 2 上の視線追跡](eye-tracking.md)
* [視線入力とコミット](gaze-and-commit.md)
* [視線入力とドウェル](gaze-and-dwell.md)
* [手 - 直接操作](direct-manipulation.md)
* [手 - ジェスチャ](gaze-and-commit.md#composite-gestures)
* [手 - ポイントとコミット](point-and-commit.md)
* [本能的な操作](interaction-fundamentals.md)
* [音声入力](voice-input.md)
