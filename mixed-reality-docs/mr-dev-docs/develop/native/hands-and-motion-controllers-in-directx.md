---
title: DirectX での手とモーション コントローラー
description: ネイティブ DirectX アプリでハンドトラッキングとモーションコントローラーを使用するための開発者ガイド。
author: caseymeekhof
ms.author: cmeekhof
ms.date: 08/04/2020
ms.topic: article
keywords: ハンド、モーションコントローラー、directx、入力、ホログラム
ms.openlocfilehash: faa9abe224b554c45cf0175b62da40c297122ad1
ms.sourcegitcommit: 09599b4034be825e4536eeb9566968afd021d5f3
ms.translationtype: MT
ms.contentlocale: ja-JP
ms.lasthandoff: 10/03/2020
ms.locfileid: "91685919"
---
# <a name="hands-and-motion-controllers-in-directx"></a><span data-ttu-id="6d3e2-104">DirectX での手とモーション コントローラー</span><span class="sxs-lookup"><span data-stu-id="6d3e2-104">Hands and motion controllers in DirectX</span></span>

> [!NOTE]
> <span data-ttu-id="6d3e2-105">この記事は、従来の WinRT ネイティブ Api に関連しています。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-105">This article relates to the legacy WinRT native APIs.</span></span>  <span data-ttu-id="6d3e2-106">新しいネイティブアプリプロジェクトの場合は、 **[OPENXR API](openxr-getting-started.md)** を使用することをお勧めします。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-106">For new native app projects, we recommend using the **[OpenXR API](openxr-getting-started.md)** .</span></span>

<span data-ttu-id="6d3e2-107">Windows Mixed Reality では、ハンドコントローラー入力と [モーションコントローラー](../../design/motion-controllers.md) 入力の両方が、windows の. [UI.](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial) 空間名前空間にある空間入力 api を介して処理されます。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-107">In Windows Mixed Reality, both hand and [motion controller](../../design/motion-controllers.md) input is handled through the spatial input APIs, found in the [Windows.UI.Input.Spatial](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial) namespace.</span></span> <span data-ttu-id="6d3e2-108">これにより、 **選択** などの一般的なアクションを簡単に処理できるようになります。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-108">This enables you to easily handle common actions like **Select** presses the same way across both hands and motion controllers.</span></span>

## <a name="getting-started"></a><span data-ttu-id="6d3e2-109">作業の開始</span><span class="sxs-lookup"><span data-stu-id="6d3e2-109">Getting started</span></span>

<span data-ttu-id="6d3e2-110">Windows Mixed Reality で空間入力にアクセスするには、SpatialInteractionManager インターフェイスから開始します。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-110">To access spatial input in Windows Mixed Reality, start with the SpatialInteractionManager interface.</span></span>  <span data-ttu-id="6d3e2-111">このインターフェイスにアクセスするには、通常はアプリの起動時に  [SpatialInteractionManager:: GetForCurrentView](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.getforcurrentview)を呼び出します。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-111">You can access this interface by calling  [SpatialInteractionManager::GetForCurrentView](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.getforcurrentview), typically sometime during app startup.</span></span>

```cpp
using namespace winrt::Windows::UI::Input::Spatial;

SpatialInteractionManager interactionManager = SpatialInteractionManager::GetForCurrentView();
```

<span data-ttu-id="6d3e2-112">SpatialInteractionManager の仕事は、入力のソースを表す [SpatialInteractionSources](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsource)へのアクセスを提供することです。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-112">The SpatialInteractionManager's job is to provide access to [SpatialInteractionSources](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsource), which represent a source of input.</span></span>  <span data-ttu-id="6d3e2-113">システムで使用できる SpatialInteractionSources には3種類あります。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-113">There are three kinds of SpatialInteractionSources available in the system.</span></span>
* <span data-ttu-id="6d3e2-114">**ハンド** は、ユーザーの検出されたハンドを表します。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-114">**Hand** represents a user's detected hand.</span></span> <span data-ttu-id="6d3e2-115">手動ソースは、HoloLens の基本的なジェスチャから HoloLens 2 の完全な形の追跡まで、デバイスに基づいてさまざまな機能を提供します。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-115">Hand sources offer different features based on the device, ranging from basic gestures on HoloLens to fully articulated hand tracking on HoloLens 2.</span></span> 
* <span data-ttu-id="6d3e2-116">**コントローラー** は、対になっているモーションコントローラーを表します。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-116">**Controller** represents a paired motion controller.</span></span> <span data-ttu-id="6d3e2-117">モーションコントローラーは、さまざまな機能を提供できます。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-117">Motion controllers can offer a variety of capabilities.</span></span>  <span data-ttu-id="6d3e2-118">たとえば、トリガー、メニューボタン、ボタン、タッチパッド向け、および thumbsticks を選択します。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-118">For example: Select triggers, Menu buttons, Grasp buttons, touchpads and thumbsticks.</span></span>
* <span data-ttu-id="6d3e2-119">**音声** は、ユーザーの音声読み上げシステムで検出されたキーワードを表します。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-119">**Voice** represents the user's voice speaking system-detected keywords.</span></span> <span data-ttu-id="6d3e2-120">たとえば、このソースでは、ユーザーが "Select" と表示されるたびに、Select press と release が挿入されます。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-120">For example, this source will inject a Select press and release whenever the user says "Select".</span></span>

<span data-ttu-id="6d3e2-121">ソースのフレームごとのデータは、  [SpatialInteractionSourceState](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate) インターフェイスによって表されます。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-121">Per-frame data for a source is represented by the  [SpatialInteractionSourceState](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate) interface.</span></span> <span data-ttu-id="6d3e2-122">アプリケーションでイベントドリブンモデルとポーリングベースのモデルのどちらを使用するかに応じて、このデータにアクセスする2つの方法があります。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-122">There are two different ways to access this data, depending on whether you want to use an event-driven or polling-based model in your application.</span></span>

### <a name="event-driven-input"></a><span data-ttu-id="6d3e2-123">イベントドリブン入力</span><span class="sxs-lookup"><span data-stu-id="6d3e2-123">Event-driven input</span></span>
<span data-ttu-id="6d3e2-124">SpatialInteractionManager は、アプリがリッスンできる多数のイベントを提供します。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-124">The SpatialInteractionManager provides a number of events that your app can listen for.</span></span>  <span data-ttu-id="6d3e2-125">例として、   [Sourcepressed](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcepressed)れた、 [SourceReleased](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcereleased) 、 [sourcepressed](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourceupdated)などがあります。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-125">A few examples include   [SourcePressed](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcepressed), [SourceReleased](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcereleased) and [SourceUpdated](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourceupdated).</span></span>

<span data-ttu-id="6d3e2-126">たとえば、次のコードは、MyApp イベントに対して MyApp:: OnSourcePressed れたイベントハンドラーをフックします。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-126">For example, the following code hooks up an event handler called MyApp::OnSourcePressed to the SourcePressed event.</span></span>  <span data-ttu-id="6d3e2-127">これにより、アプリは任意の種類の相互作用ソースの押下を検出できます。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-127">This allows your app to detect presses on any type of interaction source.</span></span>

```cpp
using namespace winrt::Windows::UI::Input::Spatial;

auto interactionManager = SpatialInteractionManager::GetForCurrentView();
interactionManager.SourcePressed({ this, &MyApp::OnSourcePressed });

```

<span data-ttu-id="6d3e2-128">この押されたイベントは、キーを押したときの対応する SpatialInteractionSourceState と共に、アプリに非同期的に送信されます。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-128">This pressed event is sent to your app asynchronously, along with the corresponding SpatialInteractionSourceState at the time the press happened.</span></span> <span data-ttu-id="6d3e2-129">アプリまたはゲームエンジンでは、すぐに処理を実行したり、入力処理ルーチンでイベントデータをキューに入れたりすることが必要になる場合があります。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-129">Your app or game engine may want to perform some processing right away or you may want to queue up the event data in your input processing routine.</span></span> <span data-ttu-id="6d3e2-130">次に示すのは、SourcePressed れたイベントのイベントハンドラー関数で、[選択] ボタンが押されたかどうかを確認する方法を示しています。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-130">Here is an event handler function for the SourcePressed event, which shows how to check whether the select button was pressed.</span></span>

```cpp
using namespace winrt::Windows::UI::Input::Spatial;

void MyApp::OnSourcePressed(SpatialInteractionManager const& sender, SpatialInteractionSourceEventArgs const& args)
{
    if (args.PressKind() == SpatialInteractionPressKind::Select)
    {
        // Select button was pressed, update app state
    }
}
```

<span data-ttu-id="6d3e2-131">上のコードでは、デバイスの主なアクションに対応する ' Select ' の押下だけがチェックされます。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-131">The above code only checks for the 'Select' press, which corresponds to the primary action on the device.</span></span> <span data-ttu-id="6d3e2-132">たとえば、HoloLens でのエアタップの実行や、モーションコントローラーでのトリガーの取り出しなどです。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-132">Examples include doing an AirTap on HoloLens or pulling the trigger on a motion controller.</span></span>  <span data-ttu-id="6d3e2-133">' Select ' は、ターゲットとしているホログラムをアクティブ化するユーザーの意図を表します。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-133">'Select' presses represent the user's intention to activate the hologram they are targeting.</span></span>  <span data-ttu-id="6d3e2-134">SourcePressed イベントは、さまざまなボタンとジェスチャに対して起動されます。また、SpatialInteractionSource の他のプロパティを調べて、そのようなケースをテストできます。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-134">The SourcePressed event will fire for a number of different buttons and gestures, and you can inspect other properties on the SpatialInteractionSource to test for those cases.</span></span>

### <a name="polling-based-input"></a><span data-ttu-id="6d3e2-135">ポーリングベースの入力</span><span class="sxs-lookup"><span data-stu-id="6d3e2-135">Polling-based input</span></span>
<span data-ttu-id="6d3e2-136">また、SpatialInteractionManager を使用して、すべてのフレームに対する入力の現在の状態をポーリングすることもできます。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-136">You can also use SpatialInteractionManager to poll for the current state of input every frame.</span></span>  <span data-ttu-id="6d3e2-137">これを行うには、すべてのフレームで [GetDetectedSourcesAtTimestamp](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.getdetectedsourcesattimestamp) を呼び出します。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-137">To do this, simply call [GetDetectedSourcesAtTimestamp](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.getdetectedsourcesattimestamp) every frame.</span></span>  <span data-ttu-id="6d3e2-138">この関数は、アクティブな[SpatialInteractionSource](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsource)ごとに1つの[SpatialInteractionSourceState](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate)を含む配列を返します。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-138">This function returns an array containing one [SpatialInteractionSourceState](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate) for every active [SpatialInteractionSource](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsource).</span></span> <span data-ttu-id="6d3e2-139">これは、アクティブなモーションコントローラーごとに1つ、つまり、' select ' コマンドが最近発音された場合は、1つずつ、もう1つは音声用です。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-139">This means one for each active motion controller, one for each tracked hand, and one for speech if a 'select' command was recently uttered.</span></span> <span data-ttu-id="6d3e2-140">その後、各 SpatialInteractionSourceState のプロパティを調べて、アプリケーションへの入力を実行できます。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-140">You can then inspect the properties on each SpatialInteractionSourceState to drive input into your application.</span></span> 

<span data-ttu-id="6d3e2-141">ポーリング方法を使用して ' select ' アクションを確認する方法の例を次に示します。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-141">Here is an example of how to check for the 'select' action using the polling method.</span></span> <span data-ttu-id="6d3e2-142">*予測* 変数は [HolographicFramePrediction](https://docs.microsoft.com//uwp/api/Windows.Graphics.Holographic.HolographicFramePrediction)オブジェクトを表すことに注意してください。これは [HolographicFrame](https://docs.microsoft.com//uwp/api/windows.graphics.holographic.holographicframe)から取得できます。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-142">Note that the *prediction* variable represents a [HolographicFramePrediction](https://docs.microsoft.com//uwp/api/Windows.Graphics.Holographic.HolographicFramePrediction) object, which can be obtained from the [HolographicFrame](https://docs.microsoft.com//uwp/api/windows.graphics.holographic.holographicframe).</span></span>

```cpp
using namespace winrt::Windows::UI::Input::Spatial;

auto interactionManager = SpatialInteractionManager::GetForCurrentView();
auto sourceStates = m_spatialInteractionManager.GetDetectedSourcesAtTimestamp(prediction.Timestamp());

for (auto& sourceState : sourceStates)
{
    if (sourceState.IsSelectPressed())
    {
        // Select button is down, update app state
    }
}
```

<span data-ttu-id="6d3e2-143">各 SpatialInteractionSource には ID があり、これを使用して新しいソースを識別し、フレーム間の既存のソースを関連付けることができます。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-143">Each SpatialInteractionSource has an ID, which you can use to identify new sources and correlate existing sources from frame to frame.</span></span>  <span data-ttu-id="6d3e2-144">ハンドは、移動するたびに新しい ID が割り当てられますが、セッションの間は、コントローラー Id は静的のままです。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-144">Hands are assigned a new ID every time they leave and enter the FOV, but controller IDs remain static for the duration of the session.</span></span>  <span data-ttu-id="6d3e2-145">[Sourcedetected](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcedetected)や[Sourcedetected](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcelost)などの SpatialInteractionManager のイベントを使用して、ユーザーがデバイスのビューを手に入れたり、移動したりしたとき、またはモーションコントローラーがオン/オフになっているとき、またはペア/対になっていないときに反応することができます。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-145">You can use the events on SpatialInteractionManager such as [SourceDetected](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcedetected) and [SourceLost](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcelost), to react when hands enter or leave the device's view, or when motion controllers are turned on/off or are paired/unpaired.</span></span>

### <a name="predicted-vs-historical-poses"></a><span data-ttu-id="6d3e2-146">予測と履歴のポーズ</span><span class="sxs-lookup"><span data-stu-id="6d3e2-146">Predicted vs. historical poses</span></span>
<span data-ttu-id="6d3e2-147">GetDetectedSourcesAtTimestamp には timestamp パラメーターがあることに注意してください。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-147">Note that GetDetectedSourcesAtTimestamp has a timestamp parameter.</span></span> <span data-ttu-id="6d3e2-148">これにより、予測または履歴の状態を要求し、データを供給することができるため、空間の相互作用を他の入力のソースと関連付けることができます。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-148">This enables you to request state and pose data that is either predicted or historical, letting you correlate spatial interactions with other sources of input.</span></span> <span data-ttu-id="6d3e2-149">たとえば、現在のフレームに手の位置を表示する場合は、 [HolographicFrame](https://docs.microsoft.com//uwp/api/windows.graphics.holographic.holographicframe)によって提供される予測タイムスタンプを渡すことができます。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-149">For example, when rendering the hand's position in the current frame, you can pass in the predicted timestamp provided by the [HolographicFrame](https://docs.microsoft.com//uwp/api/windows.graphics.holographic.holographicframe).</span></span> <span data-ttu-id="6d3e2-150">これにより、システムは、描画されたフレーム出力と密接に一致するようにハンド位置を順方向に予測して、認識される待機時間を最小限に抑えることができます。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-150">This enables the system to forward-predict the hand position to closely align with the rendered frame output, minimizing perceived latency.</span></span>

<span data-ttu-id="6d3e2-151">ただし、このような予測によって、相互作用ソースをターゲットにするための最適なポイントが生成されるわけではありません。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-151">However, such a predicted pose does not produce an ideal pointing ray for targeting with an interaction source.</span></span> <span data-ttu-id="6d3e2-152">たとえば、[モーションコントローラー] ボタンが押されている場合、そのイベントが Bluetooth 経由でオペレーティングシステムに対して20ミリ秒になるまでに最大で時間がかかることがあります。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-152">For example, when a motion controller button is pressed, it can take up to 20ms for that event to bubble up through Bluetooth to the operating system.</span></span> <span data-ttu-id="6d3e2-153">同様に、ユーザーが手の形でジェスチャを実行した後、システムがジェスチャを検出する前に一定の時間が経過し、アプリがそのジェスチャをポーリングします。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-153">Similarly, after a user performs a hand gesture, some amount of time may pass before the system detects the gesture and your app then polls for it.</span></span> <span data-ttu-id="6d3e2-154">アプリが状態の変更をポーリングするまでに、その相互作用をターゲットとするために使用されるヘッドとハンドは、実際には過去に発生しました。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-154">By the time your app polls for a state change, the head and hand poses used to target that interaction actually happened in the past.</span></span> <span data-ttu-id="6d3e2-155">現在の HolographicFrame のタイムスタンプを GetDetectedSourcesAtTimestamp に渡すことによってターゲットを設定した場合は、フレームが表示された時点でターゲットの射線に対して、予測が前方に転送されます。これは将来の20ミリ秒よりも大きくなる可能性があります。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-155">If you target by passing your current HolographicFrame's timestamp to GetDetectedSourcesAtTimestamp, the pose will instead be forward predicted to the targeting ray at the time the frame will be displayed, which could be more than 20ms in the future.</span></span> <span data-ttu-id="6d3e2-156">これは、相互作用ソースを *レンダリング* する場合に適していますが、ユーザーの対象が過去に発生したため、相互作用を *対象* とした時間の問題が複雑になります。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-156">This future pose is good for *rendering* the interaction source, but compounds our time problem for *targeting* the interaction, as the user's targeting occurred in the past.</span></span>

<span data-ttu-id="6d3e2-157">幸いなことに、 [Sourcepressed](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcepressed)れた、 [SourceReleased](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcereleased) および [sourcepressed](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourceupdated) イベントは、各入力イベントに関連付けられた履歴 [状態](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourceeventargs.state) を提供します。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-157">Fortunately, the [SourcePressed](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcepressed), [SourceReleased](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcereleased) and [SourceUpdated](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourceupdated) events provide the historical [State](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourceeventargs.state) associated with each input event.</span></span>  <span data-ttu-id="6d3e2-158">これには、 [Trygetポインター](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.trygetpointerpose)によって使用可能な履歴のヘッドとハンドのポーズと、他の api に渡してこのイベントと関連付けることができる履歴 [タイムスタンプ](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.timestamp) が含まれます。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-158">This directly includes the historical head and hand poses available through [TryGetPointerPose](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.trygetpointerpose), along with a historical [Timestamp](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.timestamp) that you can pass to other APIs to correlate with this event.</span></span>

<span data-ttu-id="6d3e2-159">次のベストプラクティスに従って、各フレームでハンドおよびコントローラーをレンダリングして対象を設定します。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-159">That leads to the following best practices when rendering and targeting with hands and controllers each frame:</span></span>
* <span data-ttu-id="6d3e2-160">各フレームを **レンダリング** するには、アプリは、現在のフレームの photon 時間における各相互作用ソースの **フォワード予測** を **ポーリング** する必要があります。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-160">For **hand/controller rendering** each frame, your app should **poll** for the **forward-predicted** pose of each interaction source at the current frame’s photon time.</span></span>  <span data-ttu-id="6d3e2-161">各フレーム [GetDetectedSourcesAtTimestamp](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.getdetectedsourcesattimestamp) を呼び出し、 [HolographicFrame:: currentprediction](https://docs.microsoft.com//uwp/api/windows.graphics.holographic.holographicframe.currentprediction)によって提供される予測タイムスタンプを渡すことによって、すべての相互作用ソースをポーリングできます。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-161">You can poll for all interaction sources by calling [GetDetectedSourcesAtTimestamp](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.getdetectedsourcesattimestamp) each frame, passing in the predicted timestamp provided by [HolographicFrame::CurrentPrediction](https://docs.microsoft.com//uwp/api/windows.graphics.holographic.holographicframe.currentprediction).</span></span>
* <span data-ttu-id="6d3e2-162">プレスまたはリリースを対象とする手動または **コントローラー** の場合、アプリでは、そのイベントの **履歴** ヘッドまたはハンド raycasting に基づいて、押されたイベントまたは解放された **イベント** を処理する必要があります。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-162">For **hand/controller targeting** upon a press or release, your app should handle pressed/released **events** , raycasting based on the **historical** head or hand pose for that event.</span></span> <span data-ttu-id="6d3e2-163">このターゲット設定を取得するには、 [Sourcepressed](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcepressed) れたイベントまたは [SourceReleased](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcereleased) イベントを処理し、イベント引数から [State](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourceeventargs.state) プロパティを取得して、その [trygetポインタポーズ](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.trygetpointerpose) メソッドを呼び出します。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-163">You get this targeting ray by handling the [SourcePressed](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcepressed) or [SourceReleased](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcereleased) event, getting the [State](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourceeventargs.state) property from the event arguments, and then calling its [TryGetPointerPose](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.trygetpointerpose) method.</span></span>

## <a name="cross-device-input-properties"></a><span data-ttu-id="6d3e2-164">デバイス間の入力プロパティ</span><span class="sxs-lookup"><span data-stu-id="6d3e2-164">Cross-device input properties</span></span>
<span data-ttu-id="6d3e2-165">SpatialInteractionSource API では、さまざまな機能を備えたコントローラーおよびハンドトラッキングシステムがサポートされています。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-165">The SpatialInteractionSource API supports controllers and hand tracking systems with a wide range of capabilities.</span></span> <span data-ttu-id="6d3e2-166">これらの機能の多くは、デバイスの種類によって一般的です。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-166">A number of these capabilities are common between device types.</span></span> <span data-ttu-id="6d3e2-167">たとえば、ハンドトラッキングとモーションコントローラーは、どちらも ' select ' アクションと3D 位置を提供します。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-167">For example, hand tracking and motion controllers both provide a 'select' action and a 3D position.</span></span> <span data-ttu-id="6d3e2-168">可能な限り、API はこれらの共通機能を SpatialInteractionSource の同じプロパティにマップします。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-168">Wherever possible, the API maps these common capabilities to the same properties on the SpatialInteractionSource.</span></span>  <span data-ttu-id="6d3e2-169">これにより、アプリケーションは幅広い種類の入力をより簡単にサポートできるようになります。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-169">This enables applications to more easily support a wide range of input types.</span></span> <span data-ttu-id="6d3e2-170">次の表では、サポートされるプロパティと、入力の種類間での比較方法について説明します。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-170">The following table describes the properties that are supported, and how they compare across input types.</span></span>

| <span data-ttu-id="6d3e2-171">プロパティ</span><span class="sxs-lookup"><span data-stu-id="6d3e2-171">Property</span></span> | <span data-ttu-id="6d3e2-172">説明</span><span class="sxs-lookup"><span data-stu-id="6d3e2-172">Description</span></span> | <span data-ttu-id="6d3e2-173">HoloLens (第1世代) ジェスチャ</span><span class="sxs-lookup"><span data-stu-id="6d3e2-173">HoloLens(1st gen) Gestures</span></span> | <span data-ttu-id="6d3e2-174">モーションコントローラー</span><span class="sxs-lookup"><span data-stu-id="6d3e2-174">Motion Controllers</span></span> | <span data-ttu-id="6d3e2-175">手によるハンド</span><span class="sxs-lookup"><span data-stu-id="6d3e2-175">Articulated Hands</span></span>|
|--- |--- |--- |--- |--- |
| [<span data-ttu-id="6d3e2-176">SpatialInteractionSource:: **きき**</span><span class="sxs-lookup"><span data-stu-id="6d3e2-176">SpatialInteractionSource:: **Handedness**</span></span>](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsource.handedness) | <span data-ttu-id="6d3e2-177">Right または left/controller。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-177">Right or left hand / controller.</span></span> | <span data-ttu-id="6d3e2-178">サポートされていません</span><span class="sxs-lookup"><span data-stu-id="6d3e2-178">Not Supported</span></span> | <span data-ttu-id="6d3e2-179">サポートされています</span><span class="sxs-lookup"><span data-stu-id="6d3e2-179">Supported</span></span> | <span data-ttu-id="6d3e2-180">サポートされています</span><span class="sxs-lookup"><span data-stu-id="6d3e2-180">Supported</span></span> |
| [<span data-ttu-id="6d3e2-181">SpatialInteractionSourceState:: **Isselectpressed** れました</span><span class="sxs-lookup"><span data-stu-id="6d3e2-181">SpatialInteractionSourceState:: **IsSelectPressed**</span></span>](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.isselectpressed) | <span data-ttu-id="6d3e2-182">プライマリボタンの現在の状態。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-182">Current state of the primary button.</span></span> | <span data-ttu-id="6d3e2-183">エアタップ</span><span class="sxs-lookup"><span data-stu-id="6d3e2-183">Air Tap</span></span> | <span data-ttu-id="6d3e2-184">トリガー</span><span class="sxs-lookup"><span data-stu-id="6d3e2-184">Trigger</span></span> | <span data-ttu-id="6d3e2-185">緩やかに出た空気タップ (垂直ピンチ)</span><span class="sxs-lookup"><span data-stu-id="6d3e2-185">Relaxed Air Tap (upright pinch)</span></span> |
| [<span data-ttu-id="6d3e2-186">SpatialInteractionSourceState:: **IsGrasped**</span><span class="sxs-lookup"><span data-stu-id="6d3e2-186">SpatialInteractionSourceState:: **IsGrasped**</span></span>](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.isgrasped) | <span data-ttu-id="6d3e2-187">グラブボタンの現在の状態です。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-187">Current state of the grab button.</span></span> | <span data-ttu-id="6d3e2-188">サポートされていません</span><span class="sxs-lookup"><span data-stu-id="6d3e2-188">Not Supported</span></span> | <span data-ttu-id="6d3e2-189">グラブボタン</span><span class="sxs-lookup"><span data-stu-id="6d3e2-189">Grab button</span></span> | <span data-ttu-id="6d3e2-190">ピンチまたは閉じた手</span><span class="sxs-lookup"><span data-stu-id="6d3e2-190">Pinch or Closed Hand</span></span> |
| [<span data-ttu-id="6d3e2-191">SpatialInteractionSourceState:: **IsMenuPressed**</span><span class="sxs-lookup"><span data-stu-id="6d3e2-191">SpatialInteractionSourceState:: **IsMenuPressed**</span></span>](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.ismenupressed) | <span data-ttu-id="6d3e2-192">メニューボタンの現在の状態。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-192">Current state of the menu button.</span></span>    | <span data-ttu-id="6d3e2-193">サポートされていません</span><span class="sxs-lookup"><span data-stu-id="6d3e2-193">Not Supported</span></span> | <span data-ttu-id="6d3e2-194">メニューボタン</span><span class="sxs-lookup"><span data-stu-id="6d3e2-194">Menu Button</span></span> | <span data-ttu-id="6d3e2-195">サポートされていません</span><span class="sxs-lookup"><span data-stu-id="6d3e2-195">Not Supported</span></span> |
| [<span data-ttu-id="6d3e2-196">SpatialInteractionSourceLocation:: **Position**</span><span class="sxs-lookup"><span data-stu-id="6d3e2-196">SpatialInteractionSourceLocation:: **Position**</span></span>](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcelocation.position) | <span data-ttu-id="6d3e2-197">コントローラー上の手またはグリップ位置の XYZ 位置。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-197">XYZ location of the hand or grip position on the controller.</span></span> | <span data-ttu-id="6d3e2-198">パームの場所</span><span class="sxs-lookup"><span data-stu-id="6d3e2-198">Palm location</span></span> | <span data-ttu-id="6d3e2-199">グリップの発生位置</span><span class="sxs-lookup"><span data-stu-id="6d3e2-199">Grip pose position</span></span> | <span data-ttu-id="6d3e2-200">パームの場所</span><span class="sxs-lookup"><span data-stu-id="6d3e2-200">Palm location</span></span> |
| [<span data-ttu-id="6d3e2-201">SpatialInteractionSourceLocation:: **Orientation**</span><span class="sxs-lookup"><span data-stu-id="6d3e2-201">SpatialInteractionSourceLocation:: **Orientation**</span></span>](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcelocation.orientation) | <span data-ttu-id="6d3e2-202">コントローラー上の手やグリップの向きを表す四元数。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-202">Quaternion representing the orientation of the hand or grip pose on the controller.</span></span> | <span data-ttu-id="6d3e2-203">サポートされていません</span><span class="sxs-lookup"><span data-stu-id="6d3e2-203">Not Supported</span></span> | <span data-ttu-id="6d3e2-204">グリップの向き</span><span class="sxs-lookup"><span data-stu-id="6d3e2-204">Grip pose orientation</span></span> | <span data-ttu-id="6d3e2-205">パームの向き</span><span class="sxs-lookup"><span data-stu-id="6d3e2-205">Palm orientation</span></span> |
| [<span data-ttu-id="6d3e2-206">SpatialPointerInteractionSourcePose:: **Position**</span><span class="sxs-lookup"><span data-stu-id="6d3e2-206">SpatialPointerInteractionSourcePose:: **Position**</span></span>](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialpointerinteractionsourcepose.position#Windows_UI_Input_Spatial_SpatialPointerInteractionSourcePose_Position) | <span data-ttu-id="6d3e2-207">ポイントの原点。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-207">Origin of the pointing ray.</span></span> | <span data-ttu-id="6d3e2-208">サポートされていません</span><span class="sxs-lookup"><span data-stu-id="6d3e2-208">Not Supported</span></span> | <span data-ttu-id="6d3e2-209">サポートされています</span><span class="sxs-lookup"><span data-stu-id="6d3e2-209">Supported</span></span> | <span data-ttu-id="6d3e2-210">サポートされています</span><span class="sxs-lookup"><span data-stu-id="6d3e2-210">Supported</span></span> |
| [<span data-ttu-id="6d3e2-211">SpatialPointerInteractionSourcePose:: **Forwarddirection**</span><span class="sxs-lookup"><span data-stu-id="6d3e2-211">SpatialPointerInteractionSourcePose:: **ForwardDirection**</span></span>](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialpointerinteractionsourcepose.forwarddirection#Windows_UI_Input_Spatial_SpatialPointerInteractionSourcePose_ForwardDirection) | <span data-ttu-id="6d3e2-212">ポイントの方向。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-212">Direction of the pointing ray.</span></span> | <span data-ttu-id="6d3e2-213">サポートされていません</span><span class="sxs-lookup"><span data-stu-id="6d3e2-213">Not Supported</span></span> | <span data-ttu-id="6d3e2-214">サポートされています</span><span class="sxs-lookup"><span data-stu-id="6d3e2-214">Supported</span></span> | <span data-ttu-id="6d3e2-215">サポートされています</span><span class="sxs-lookup"><span data-stu-id="6d3e2-215">Supported</span></span> |

<span data-ttu-id="6d3e2-216">上記のプロパティの一部は、すべてのデバイスで使用できるわけではありません。 API には、このことをテストする手段が用意されています。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-216">Some of the above properties are not available on all devices, and the API provides a means to test for this.</span></span> <span data-ttu-id="6d3e2-217">たとえば、 [SpatialInteractionSource:: IsGraspSupported](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsource.isgraspsupported) プロパティを調べて、ソースがつかみアクションを提供するかどうかを判断できます。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-217">For example, you can inspect the [SpatialInteractionSource::IsGraspSupported](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsource.isgraspsupported) property to determine whether the source provides a grasp action.</span></span>

### <a name="grip-pose-vs-pointing-pose"></a><span data-ttu-id="6d3e2-218">グリップポーズとポインティングポーズ</span><span class="sxs-lookup"><span data-stu-id="6d3e2-218">Grip pose vs. pointing pose</span></span>

<span data-ttu-id="6d3e2-219">Windows Mixed Reality では、さまざまなフォームファクターでモーションコントローラーをサポートしています。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-219">Windows Mixed Reality supports motion controllers in a variety of form factors.</span></span>  <span data-ttu-id="6d3e2-220">また、独自の追跡システムもサポートしています。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-220">It also supports articulated hand tracking systems.</span></span>  <span data-ttu-id="6d3e2-221">これらのシステムはすべて、ユーザーの手の中でオブジェクトをポイントまたは表示するためにアプリが使用する必要がある自然な位置と自然な "転送" 方向との間には異なる関係があります。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-221">All of these systems have different relationships between the hand position and the natural "forward" direction that apps should use for pointing or rendering objects in the user's hand.</span></span>  <span data-ttu-id="6d3e2-222">これらのすべてをサポートするために、ハンドトラッキングとモーションコントローラーの両方に3種類の3D が用意されています。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-222">To support all of this, there are two types of 3D poses provided for both hand tracking and motion controllers.</span></span>  <span data-ttu-id="6d3e2-223">1つ目は、ユーザーの手の位置を表すグリップです。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-223">The first is grip pose, which represents the user's hand position.</span></span>  <span data-ttu-id="6d3e2-224">2つ目の方法は、ユーザーの手またはコントローラーからのポイントを示すポイントを指します。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-224">The second is pointing pose, which represents a pointing ray originating from the user's hand or controller.</span></span> <span data-ttu-id="6d3e2-225">そのため、 **ユーザーの手** や、剣や銃などの **ユーザーの手に保持** されているオブジェクトをレンダリングする場合は、グリップを使用します。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-225">So, if you want to render **the user's hand** or **an object held in the user's hand** , such as a sword or gun, use the grip pose.</span></span> <span data-ttu-id="6d3e2-226">ユーザーが **UI をポイント** しているときなど、コントローラーまたはハンドから raycast する場合は、ポイントアンドポーズを使用します。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-226">If you want to raycast from the controller or hand, for example when the user is **pointing at UI** , use the pointing pose.</span></span>

<span data-ttu-id="6d3e2-227">**グリップ** にアクセスするには、 [SpatialInteractionSourceState::P R.:: trygetlocation (...)](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourceproperties.trygetlocation#Windows_UI_Input_Spatial_SpatialInteractionSourceProperties_TryGetLocation_Windows_Perception_Spatial_SpatialCoordinateSystem_)を使用します。 次のように定義されています。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-227">You can access the **grip pose** through [SpatialInteractionSourceState::Properties::TryGetLocation(...)](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourceproperties.trygetlocation#Windows_UI_Input_Spatial_SpatialInteractionSourceProperties_TryGetLocation_Windows_Perception_Spatial_SpatialCoordinateSystem_).  It is defined as follows:</span></span>
* <span data-ttu-id="6d3e2-228">**グリップの位置** : コントローラーを自然に保持するときのパーム重心。グリップ内の位置を中央に配置するように左右に調整されます。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-228">The **grip position** : The palm centroid when holding the controller naturally, adjusted left or right to center the position within the grip.</span></span>
* <span data-ttu-id="6d3e2-229">**グリップの向きの右軸** : 手を完全に開いて平らな5本の指を作成した場合 (左側のパームから前方、右側のパームから後方)、</span><span class="sxs-lookup"><span data-stu-id="6d3e2-229">The **grip orientation's Right axis** : When you completely open your hand to form a flat 5-finger pose, the ray that is normal to your palm (forward from left palm, backward from right palm)</span></span>
* <span data-ttu-id="6d3e2-230">**グリップの向きの前方軸** : ハンドを部分的に閉じた場合 (コントローラーを保持している場合と同様)、非表示の指で形成されたチューブを通過する光線。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-230">The **grip orientation's Forward axis** : When you close your hand partially (as if holding the controller), the ray that points "forward" through the tube formed by your non-thumb fingers.</span></span>
* <span data-ttu-id="6d3e2-231">**グリップの向きの上位軸** : 右および順方向の定義によって暗黙的に示される上位軸。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-231">The **grip orientation's Up axis** : The Up axis implied by the Right and Forward definitions.</span></span>

<span data-ttu-id="6d3e2-232">**ポインター** の [SpatialInteractionSourceState::P R.:: trygetlocation (...):: sourcepointer ポーズ](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial.spatialinteractionsourcelocation#Windows_UI_Input_Spatial_SpatialInteractionSourceLocation_SourcePointerPose)または [SpatialInteractionSourceState:: trygetlocation ポーズ (...):: Trygetinteractionsourceポーズ](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial.spatialpointerpose#Windows_UI_Input_Spatial_SpatialPointerPose_TryGetInteractionSourcePose_Windows_UI_Input_Spatial_SpatialInteractionSource_)にアクセスできます。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-232">You can access the **pointer pose** through [SpatialInteractionSourceState::Properties::TryGetLocation(...)::SourcePointerPose](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial.spatialinteractionsourcelocation#Windows_UI_Input_Spatial_SpatialInteractionSourceLocation_SourcePointerPose) or [SpatialInteractionSourceState::TryGetPointerPose(...)::TryGetInteractionSourcePose](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial.spatialpointerpose#Windows_UI_Input_Spatial_SpatialPointerPose_TryGetInteractionSourcePose_Windows_UI_Input_Spatial_SpatialInteractionSource_).</span></span>

## <a name="controller-specific-input-properties"></a><span data-ttu-id="6d3e2-233">コントローラー固有の入力プロパティ</span><span class="sxs-lookup"><span data-stu-id="6d3e2-233">Controller-specific input properties</span></span>
<span data-ttu-id="6d3e2-234">コントローラーの場合、SpatialInteractionSource には追加機能を持つコントローラープロパティがあります。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-234">For controllers, the SpatialInteractionSource has a Controller property with additional capabilities.</span></span>
* <span data-ttu-id="6d3e2-235">**Hasthumbstick:** True の場合、コントローラーにはサムスティックがあります。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-235">**HasThumbstick:** If true, the controller has a thumbstick.</span></span> <span data-ttu-id="6d3e2-236">SpatialInteractionSourceState の " [コントローラーのプロパティ](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial.spatialinteractioncontrollerproperties) " プロパティを調べて、スティックの x 値と y 値 (ThumbstickX と ThumbstickY) と押された状態 (IsThumbstickPressed) を取得します。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-236">Inspect the [ControllerProperties](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial.spatialinteractioncontrollerproperties) property of the SpatialInteractionSourceState to acquire the thumbstick x and y values (ThumbstickX and ThumbstickY), as well as its pressed state (IsThumbstickPressed).</span></span>
* <span data-ttu-id="6d3e2-237">**HasTouchpad:** True の場合、コントローラーにはタッチパッドがあります。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-237">**HasTouchpad:** If true, the controller has a touchpad.</span></span> <span data-ttu-id="6d3e2-238">SpatialInteractionSourceState の "コントローラーのプロパティ" プロパティを調べて、タッチパッドの x 値と y 値 (TouchpadX と TouchpadY) を取得し、ユーザーがパッドに触れている (IsTouchpadTouched) ことを確認し、タッチパッドを押す (Istouchpadtouched れた) かどうかを確認します。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-238">Inspect the ControllerProperties property of the SpatialInteractionSourceState to acquire the touchpad x and y values (TouchpadX and TouchpadY), and to know if the user is touching the pad (IsTouchpadTouched) and if they are pressing the touchpad down (IsTouchpadPressed).</span></span>
* <span data-ttu-id="6d3e2-239">**SimpleHapticsController:** コントローラーの SimpleHapticsController API を使用すると、コントローラーの haptics 機能を調べることができます。また、haptic フィードバックを制御することもできます。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-239">**SimpleHapticsController:** The SimpleHapticsController API for the controller allows you to inspect the haptics capabilities of the controller, and it also allows you to control haptic feedback.</span></span>

<span data-ttu-id="6d3e2-240">タッチパッドとサムスティックの範囲は、両方の軸 (下から上、左から右) に対して-1 から1までの範囲であることに注意してください。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-240">Note that the range for touchpad and thumbstick is -1 to 1 for both axes (from bottom to top, and from left to right).</span></span> <span data-ttu-id="6d3e2-241">SpatialInteractionSourceState:: SelectPressedValue プロパティを使用してアクセスされる、アナログトリガーの範囲には、0 ~ 1 の範囲があります。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-241">The range for the analog trigger, which is accessed using the SpatialInteractionSourceState::SelectPressedValue property, has a range of 0 to 1.</span></span> <span data-ttu-id="6d3e2-242">値1は、IsSelectPressed れた値が true であると相関します。その他の値は、IsSelectPressed れた値が false と関連付けられます。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-242">A value of 1 correlates with IsSelectPressed being equal to true; any other value correlates with IsSelectPressed being equal to false.</span></span>

## <a name="articulated-hand-tracking"></a><span data-ttu-id="6d3e2-243">手による追跡</span><span class="sxs-lookup"><span data-stu-id="6d3e2-243">Articulated hand tracking</span></span>
<span data-ttu-id="6d3e2-244">Windows Mixed Reality API は、HoloLens 2 でのように、独自の追跡を完全にサポートしています。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-244">The Windows Mixed Reality API provides full support for articulated hand tracking, for example on HoloLens 2.</span></span> <span data-ttu-id="6d3e2-245">独自の追跡を使用すると、アプリケーションに直接操作やポイントアンドコミット入力モデルを実装できます。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-245">Articulated hand tracking can be used to implement direct manipulation and point-and-commit input models in your applications.</span></span> <span data-ttu-id="6d3e2-246">また、完全にカスタムな対話を作成するために使用することもできます。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-246">It can also be used to author fully custom interactions.</span></span>

### <a name="hand-skeleton"></a><span data-ttu-id="6d3e2-247">手スケルトン</span><span class="sxs-lookup"><span data-stu-id="6d3e2-247">Hand skeleton</span></span>
<span data-ttu-id="6d3e2-248">トレーラー型の追跡では、さまざまな種類の相互作用を可能にする25のジョイントスケルトンが提供されます。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-248">Articulated hand tracking provides a 25 joint skeleton that enables many different types of interactions.</span></span>  <span data-ttu-id="6d3e2-249">スケルトンには、インデックス/中間/リング/リトルフィンガー、4個の関節 (つまみ)、および1つの手首結合に対して5つの接合が用意されています。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-249">The skeleton provides 5 joints for the index/middle/ring/little fingers, 4 joints for the thumb, and 1 wrist joint.</span></span>  <span data-ttu-id="6d3e2-250">この手首は、階層のベースとして機能します。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-250">The wrist joint serves as the base of the hierarchy.</span></span> <span data-ttu-id="6d3e2-251">次の図は、スケルトンのレイアウトを示しています。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-251">The following picture illustrates the layout of the skeleton.</span></span>

![手スケルトン](images/hand-skeleton.png)

<span data-ttu-id="6d3e2-253">ほとんどの場合、各結合には、それが表すボーンに基づいた名前が付けられます。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-253">In most cases, each joint is named based on the bone that it represents.</span></span>  <span data-ttu-id="6d3e2-254">すべてのジョイントに2つのボーンがあるため、その場所の子ボーンに基づいて各結合に名前を付ける規則を使用します。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-254">Since there are two bones at every joint, we use a convention of naming each joint based on the child bone at that location.</span></span>  <span data-ttu-id="6d3e2-255">子ボーンは、手首からさらにボーンとして定義されます。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-255">The child bone is defined as the bone further from the wrist.</span></span>  <span data-ttu-id="6d3e2-256">たとえば、"Index 位" という結合には、インデックス位ボーンの開始位置とそのボーンの方向が含まれます。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-256">For example, the "Index Proximal" joint contains the beginning position of the index proximal bone, and the orientation of that bone.</span></span>  <span data-ttu-id="6d3e2-257">これには、ボーンの終了位置は含まれません。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-257">It does not contain the ending position of the bone.</span></span>  <span data-ttu-id="6d3e2-258">これが必要な場合は、階層内の次の結合 ("中間インデックス" という結合) から取得します。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-258">If you need that, you'd get it from the next joint in the hierarchy, the "Index Intermediate" joint.</span></span>

<span data-ttu-id="6d3e2-259">25の階層結合に加えて、システムには、パームジョイントが用意されています。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-259">In addition to the 25 hierarchical joints, the system provides a palm joint.</span></span>  <span data-ttu-id="6d3e2-260">通常、palm は骨格構造の一部とは見なされません。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-260">The palm is not typically considered part of the skeletal structure.</span></span>  <span data-ttu-id="6d3e2-261">これは、手の形と向きを取得するための便利な方法としてのみ提供されています。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-261">It is provided only as a convenient way to get the hand's overall position and orientation.</span></span>

<span data-ttu-id="6d3e2-262">各結合について、次の情報が提供されています。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-262">The following information is provided for each joint:</span></span>

| <span data-ttu-id="6d3e2-263">名前</span><span class="sxs-lookup"><span data-stu-id="6d3e2-263">Name</span></span> | <span data-ttu-id="6d3e2-264">説明</span><span class="sxs-lookup"><span data-stu-id="6d3e2-264">Description</span></span> |
|--- |--- |
|<span data-ttu-id="6d3e2-265">[位置]</span><span class="sxs-lookup"><span data-stu-id="6d3e2-265">Position</span></span> | <span data-ttu-id="6d3e2-266">要求されたすべての座標系で使用可能な、ジョイントの3D 位置。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-266">3D position of the joint, available in any requested coordinate system.</span></span> |
|<span data-ttu-id="6d3e2-267">方向</span><span class="sxs-lookup"><span data-stu-id="6d3e2-267">Orientation</span></span> | <span data-ttu-id="6d3e2-268">要求されたすべての座標系で使用可能な、ボーンの3D の向き。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-268">3D orientation of the bone, available in any requested coordinate system.</span></span> |
|<span data-ttu-id="6d3e2-269">Radius</span><span class="sxs-lookup"><span data-stu-id="6d3e2-269">Radius</span></span> | <span data-ttu-id="6d3e2-270">ジョイント位置のスキンの表面までの距離。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-270">Distance to surface of the skin at the joint position.</span></span> <span data-ttu-id="6d3e2-271">指の幅に依存する直接の対話や視覚エフェクトをチューニングする場合に便利です。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-271">Useful for tuning direct interactions or visualizations that rely on finger width.</span></span> |
|<span data-ttu-id="6d3e2-272">精度</span><span class="sxs-lookup"><span data-stu-id="6d3e2-272">Accuracy</span></span> | <span data-ttu-id="6d3e2-273">この共同の情報についてシステムがどの程度自信を持っているかについてのヒントを提供します。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-273">Provides a hint on how confident the system feels about this joint's information.</span></span> |

<span data-ttu-id="6d3e2-274">[SpatialInteractionSourceState](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate)の関数を使用して、ハンドスケルトンデータにアクセスできます。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-274">You can access the hand skeleton data through a function on the [SpatialInteractionSourceState](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate).</span></span>  <span data-ttu-id="6d3e2-275">関数は [TryGetHandPose](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.trygethandpose#Windows_UI_Input_Spatial_SpatialInteractionSourceState_TryGetHandPose)と呼ばれ、この関数は、"" と [いう名前の](https://docs.microsoft.com//uwp/api/windows.perception.people.handpose)オブジェクトを返します。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-275">The function is called [TryGetHandPose](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.trygethandpose#Windows_UI_Input_Spatial_SpatialInteractionSourceState_TryGetHandPose), and it returns an object called [HandPose](https://docs.microsoft.com//uwp/api/windows.perception.people.handpose).</span></span>  <span data-ttu-id="6d3e2-276">変換元が変換をサポートしていない場合、この関数は null を返します。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-276">If the source does not support articulated hands, then this function will return null.</span></span>  <span data-ttu-id="6d3e2-277">手を付けたら、 [Trygetjoint](https://docs.microsoft.com//uwp/api/windows.perception.people.handpose.trygetjoint#Windows_Perception_People_HandPose_TryGetJoint_Windows_Perception_Spatial_SpatialCoordinateSystem_Windows_Perception_People_HandJointKind_Windows_Perception_People_JointPose__)を呼び出して現在のジョイントデータを取得できます。これには、興味のあるジョイントの名前を付けます。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-277">Once you have a HandPose, you can get current joint data by calling [TryGetJoint](https://docs.microsoft.com//uwp/api/windows.perception.people.handpose.trygetjoint#Windows_Perception_People_HandPose_TryGetJoint_Windows_Perception_Spatial_SpatialCoordinateSystem_Windows_Perception_People_HandJointKind_Windows_Perception_People_JointPose__), with the name of the joint you are interested in.</span></span>  <span data-ttu-id="6d3e2-278">データは [JointPose](https://docs.microsoft.com//uwp/api/windows.perception.people.jointpose) 構造体として返されます。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-278">The data is returned as a [JointPose](https://docs.microsoft.com//uwp/api/windows.perception.people.jointpose) structure.</span></span>  <span data-ttu-id="6d3e2-279">次のコードは、インデックスのフィンガーヒントの位置を取得します。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-279">The following code gets the position of the index finger tip.</span></span> <span data-ttu-id="6d3e2-280">変数は [SpatialInteractionSourceState](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate)の *インスタンスを表し* ます。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-280">The variable *currentState* represents an instance of [SpatialInteractionSourceState](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate).</span></span>

```cpp
using namespace winrt::Windows::Perception::People;
using namespace winrt::Windows::Foundation::Numerics;

auto handPose = currentState.TryGetHandPose();
if (handPose)
{
    JointPose joint;
    if (handPose.TryGetJoint(desiredCoordinateSystem, HandJointKind::IndexTip, joint))
    {
        float3 indexTipPosition = joint.Position;

        // Do something with the index tip position
    }
}
```

### <a name="hand-mesh"></a><span data-ttu-id="6d3e2-281">手動メッシュ</span><span class="sxs-lookup"><span data-stu-id="6d3e2-281">Hand mesh</span></span>

<span data-ttu-id="6d3e2-282">修飾されたハンドトラッキング API を使用すると、完全に非フォーム化可能な三角形ハンドメッシュが可能になります。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-282">The articulated hand tracking API allows for a fully deformable triangle hand mesh.</span></span>  <span data-ttu-id="6d3e2-283">このメッシュは、ハンドスケルトンと共にリアルタイムで変形できます。また、視覚化や高度な物理手法にも役立ちます。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-283">This mesh can deform in real time along with the hand skeleton, and is useful for visualization as well as advanced physics techniques.</span></span>  <span data-ttu-id="6d3e2-284">手メッシュにアクセスするには、最初に[SpatialInteractionSource](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsource)で[TryCreateHandMeshObserverAsync](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsource.trycreatehandmeshobserverasync)を呼び出して[HandMeshObserver](https://docs.microsoft.com//uwp/api/windows.perception.people.handmeshobserver)オブジェクトを作成する必要があります。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-284">To access the hand mesh, you need to first create a [HandMeshObserver](https://docs.microsoft.com//uwp/api/windows.perception.people.handmeshobserver) object by calling [TryCreateHandMeshObserverAsync](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsource.trycreatehandmeshobserverasync) on the [SpatialInteractionSource](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsource).</span></span>  <span data-ttu-id="6d3e2-285">これは、ソースごとに1回だけ実行する必要があります。通常は、最初に表示されます。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-285">This only needs to be done once per source, typically the first time you see it.</span></span>  <span data-ttu-id="6d3e2-286">つまり、この関数を呼び出して、手動で視界に入ったときに HandMeshObserver オブジェクトを作成します。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-286">That means you'll call this function to create a HandMeshObserver object whenever a hand enters the FOV.</span></span>  <span data-ttu-id="6d3e2-287">これは非同期関数であるため、ここで少しの同時実行を処理する必要があります。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-287">Note that this is an async function, so you'll have to deal with a bit of concurrency here.</span></span>  <span data-ttu-id="6d3e2-288">使用できるようになったら、 [GetTriangleIndices](https://docs.microsoft.com//uwp/api/windows.perception.people.handmeshobserver.gettriangleindices#Windows_Perception_People_HandMeshObserver_GetTriangleIndices_System_UInt16___)を呼び出して、三角形インデックスバッファーの HandMeshObserver オブジェクトに要求できます。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-288">Once available, you can ask the HandMeshObserver object for the triangle index buffer by calling [GetTriangleIndices](https://docs.microsoft.com//uwp/api/windows.perception.people.handmeshobserver.gettriangleindices#Windows_Perception_People_HandMeshObserver_GetTriangleIndices_System_UInt16___).</span></span>  <span data-ttu-id="6d3e2-289">インデックスはフレームに対して変更されないため、これらを一度取得し、ソースの有効期間にわたってキャッシュすることができます。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-289">Indices don't change frame over frame, so you can get those once and cache them for the lifetime of the source.</span></span>  <span data-ttu-id="6d3e2-290">インデックスは、回転順に指定します。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-290">Indices are provided in clockwise winding order.</span></span>

<span data-ttu-id="6d3e2-291">次のコードは、切り離された std:: thread をスピンアップしてメッシュオブザーバーを作成し、メッシュオブザーバーが使用可能になったときにインデックスバッファーを抽出します。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-291">The following code spins up a detached std::thread to create the mesh observer and extracts the index buffer once the mesh observer is available.</span></span>  <span data-ttu-id="6d3e2-292">SpatialInteractionSourceState と呼ばれる変数から開始します。これ *は、追跡* されたハンドを表す、 [SpatialInteractionSourceState](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate)のインスタンスです。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-292">It starts from a variable called *currentState* , which is an instance of [SpatialInteractionSourceState](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate) representing a tracked hand.</span></span>

```cpp
using namespace Windows::Perception::People;

std::thread createObserverThread([this, currentState]()
{
    HandMeshObserver newHandMeshObserver = currentState.Source().TryCreateHandMeshObserverAsync().get();
    if (newHandMeshObserver)
    {
        unsigned indexCount = newHandMeshObserver.TriangleIndexCount();
        vector<unsigned short> indices(indexCount);
        newHandMeshObserver.GetTriangleIndices(indices);

        // Save the indices and handMeshObserver for later use - and use a mutex to synchronize access if needed!
     }
});
createObserverThread.detach();
```
<span data-ttu-id="6d3e2-293">デタッチされたスレッドの開始は、非同期呼び出しを処理するためのオプションの1つにすぎません。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-293">Starting a detached thread is just one option for handling async calls.</span></span>  <span data-ttu-id="6d3e2-294">または、C++/winrtでサポートされている新しい [co_await](https://docs.microsoft.com//windows/uwp/cpp-and-winrt-apis/concurrency) 機能を使用することもできます。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-294">Alternatively, you could use the new [co_await](https://docs.microsoft.com//windows/uwp/cpp-and-winrt-apis/concurrency) functionality supported by C++/WinRT.</span></span>

<span data-ttu-id="6d3e2-295">HandMeshObserver オブジェクトを作成したら、それに対応する SpatialInteractionSource がアクティブになるまで、そのオブジェクトを保持する必要があります。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-295">Once you have a HandMeshObserver object, you should hold onto it for the duration that its corresponding SpatialInteractionSource is active.</span></span>  <span data-ttu-id="6d3e2-296">次に、各フレームに対して、 [Getvertexstateforpose](https://docs.microsoft.com//uwp/api/windows.perception.people.handmeshobserver.getvertexstateforpose) を呼び出して、頂点の対象と [なるポーズを](https://docs.microsoft.com//uwp/api/windows.perception.people.handpose) 表すのに渡すことによって、ハンドを表す最新の頂点バッファーを要求できます。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-296">Then each frame, you can ask it for the latest vertex buffer that represents the hand by calling [GetVertexStateForPose](https://docs.microsoft.com//uwp/api/windows.perception.people.handmeshobserver.getvertexstateforpose) and passing in a [HandPose](https://docs.microsoft.com//uwp/api/windows.perception.people.handpose) instance that represents the pose that you want vertices for.</span></span>  <span data-ttu-id="6d3e2-297">バッファー内の各頂点は、位置と法線を持ちます。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-297">Each vertex in the buffer has a position and a normal.</span></span>  <span data-ttu-id="6d3e2-298">手メッシュの頂点の現在のセットを取得する方法の例を次に示します。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-298">Here's an example of how to get the current set of vertices for a hand mesh.</span></span>  <span data-ttu-id="6d3e2-299">前と同様に、 [SpatialInteractionSourceState](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate)*変数は、の* インスタンスを表します。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-299">Just as before, the *currentState* variable represents an instance of [SpatialInteractionSourceState](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate).</span></span>

```cpp
using namespace winrt::Windows::Perception::People;

auto handPose = currentState.TryGetHandPose();
if (handPose)
{
    std::vector<HandMeshVertex> vertices(handMeshObserver.VertexCount());
    auto vertexState = handMeshObserver.GetVertexStateForPose(handPose);
    vertexState.GetVertices(vertices);

    auto meshTransform = vertexState.CoordinateSystem().TryGetTransformTo(desiredCoordinateSystem);
    if (meshTransform != nullptr)
    {
        // Do something with the vertices and mesh transform, along with the indices that you saved earlier
    }
}
```

<span data-ttu-id="6d3e2-300">スケルトンジョイントとは対照的に、ハンドメッシュ API では、頂点の座標系を指定することはできません。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-300">In contrast to skeleton joints, the hand mesh API does not allow you to specify a coordinate system for the vertices.</span></span>  <span data-ttu-id="6d3e2-301">代わりに、 [HandMeshVertexState](https://docs.microsoft.com//uwp/api/windows.perception.people.handmeshvertexstate) は、頂点が提供される座標系を指定します。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-301">Instead, the [HandMeshVertexState](https://docs.microsoft.com//uwp/api/windows.perception.people.handmeshvertexstate) specifies the coordinate system that the vertices are provided in.</span></span>  <span data-ttu-id="6d3e2-302">次 [に、Trygettransformto](https://docs.microsoft.com//uwp/api/windows.perception.spatial.spatialcoordinatesystem.trygettransformto#Windows_Perception_Spatial_SpatialCoordinateSystem_TryGetTransformTo_Windows_Perception_Spatial_SpatialCoordinateSystem_) 呼び出して必要な座標系を指定することで、メッシュ変換を取得できます。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-302">You can then get a mesh transform by calling [TryGetTransformTo](https://docs.microsoft.com//uwp/api/windows.perception.spatial.spatialcoordinatesystem.trygettransformto#Windows_Perception_Spatial_SpatialCoordinateSystem_TryGetTransformTo_Windows_Perception_Spatial_SpatialCoordinateSystem_) and specifying your desired coordinate system.</span></span>  <span data-ttu-id="6d3e2-303">頂点を操作するときは常に、このメッシュ変換を使用する必要があります。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-303">You'll need to use this mesh transform whenever you work with the vertices.</span></span>  <span data-ttu-id="6d3e2-304">この方法では、特にレンダリング専用のメッシュを使用している場合に、CPU のオーバーヘッドが軽減されます。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-304">This approach reduces CPU overhead, especially if you are only using the mesh for rendering purposes.</span></span>

## <a name="gaze-and-commit-composite-gestures"></a><span data-ttu-id="6d3e2-305">複合ジェスチャを見つめてコミットする</span><span class="sxs-lookup"><span data-stu-id="6d3e2-305">Gaze and Commit composite gestures</span></span>
<span data-ttu-id="6d3e2-306">特に HoloLens (最初の gen) で、SpatialGestureRecognizer 入力モデルを使用するアプリケーションの場合、空間入力 API は省略可能な[SpatialGestureRecognizer](https://msdn.microsoft.com/library/windows/apps/windows.ui.input.spatial.spatialgesturerecognizer.aspx)を提供します。このオプションを使用して、"select" イベントの上に構築された複合ジェスチャを有効にすることができます。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-306">For applications using the gaze-and-commit input model, particularly on HoloLens (first gen), the Spatial Input API provides an optional [SpatialGestureRecognizer](https://msdn.microsoft.com/library/windows/apps/windows.ui.input.spatial.spatialgesturerecognizer.aspx) that can be used to to enable composite gestures built on top of the 'select' event.</span></span>  <span data-ttu-id="6d3e2-307">アプリでは、SpatialInteractionManager からホログラムの SpatialGestureRecognizer に対する相互作用をルーティングすることにより、手動での押下と解放を処理することなく、両手、音声、および空間入力デバイス全体で、タップ、ホールド、操作、およびナビゲーションイベントを一貫して検出できます。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-307">By routing interactions from the SpatialInteractionManager to a hologram's SpatialGestureRecognizer, apps can detect Tap, Hold, Manipulation, and Navigation events uniformly across hands, voice, and spatial input devices, without having to handle presses and releases manually.</span></span>

<span data-ttu-id="6d3e2-308">SpatialGestureRecognizer は、要求した一連のジェスチャ間で最小限のあいまいさだけを実行します。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-308">SpatialGestureRecognizer performs only the minimal disambiguation between the set of gestures that you request.</span></span> <span data-ttu-id="6d3e2-309">たとえば、Tap を要求した場合、ユーザーは指を好きな限り下に置くことができ、タップが引き続き発生する可能性があります。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-309">For example, if you request just Tap, the user may hold their finger down as long as they like and a Tap will still occur.</span></span> <span data-ttu-id="6d3e2-310">タップとホールドの両方を要求した場合、指を押したままにしておくと、ジェスチャがホールドに昇格し、タップが発生しなくなります。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-310">If you request both Tap and Hold, after about a second of holding down their finger, the gesture will promote to a Hold and a Tap will no longer occur.</span></span>

<span data-ttu-id="6d3e2-311">SpatialGestureRecognizer を使用するには、SpatialInteractionManager の [Interactiondetected](https://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialInteractionManager.InteractionDetected) イベントを処理し、そこで公開されている SpatialPointerPose を取得します。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-311">To use SpatialGestureRecognizer, handle the SpatialInteractionManager's [InteractionDetected](https://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialInteractionManager.InteractionDetected) event and grab the SpatialPointerPose exposed there.</span></span> <span data-ttu-id="6d3e2-312">ユーザーがどのような操作を行っているかを判断するために、ユーザーの周囲のホログラムとサーフェスメッシュとの交差部分を使用して、ユーザーの頭を見つめます。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-312">Use the user's head gaze ray from this pose to intersect with the holograms and surface meshes in the user's surroundings, in order to determine what the user is intending to interact with.</span></span> <span data-ttu-id="6d3e2-313">次に、 [CaptureInteraction](https://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialGestureRecognizer.CaptureInteraction) メソッドを使用して、イベント引数の SpatialInteraction をターゲットホログラムの SpatialGestureRecognizer にルーティングします。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-313">Then, route the SpatialInteraction in the event arguments to the target hologram's SpatialGestureRecognizer, using its [CaptureInteraction](https://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialGestureRecognizer.CaptureInteraction) method.</span></span> <span data-ttu-id="6d3e2-314">これにより、作成時に、または[TrySetGestureSettings](https://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialGestureRecognizer.TrySetGestureSettings)によって、その認識エンジンで設定された[SpatialGestureSettings](https://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialGestureSettings)に従って、その相互作用の解釈が開始されます。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-314">This starts interpreting that interaction according to the [SpatialGestureSettings](https://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialGestureSettings) set on that recognizer at creation time - or by [TrySetGestureSettings](https://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialGestureRecognizer.TrySetGestureSettings).</span></span>

<span data-ttu-id="6d3e2-315">HoloLens (最初の世代) では、相互作用とジェスチャは、通常、ユーザーのヘッドからのターゲットを導き出す必要があります。これは、直接の位置でのレンダリングや対話を試行することではありません。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-315">On HoloLens (first gen), interactions and gestures should generally derive their targeting from the user's head gaze, rather than trying to render or interact at the hand's location directly.</span></span> <span data-ttu-id="6d3e2-316">相互作用が開始されたら、操作やナビゲーションジェスチャと同様に、ハンドの相対的な動きを使ってジェスチャを制御できます。</span><span class="sxs-lookup"><span data-stu-id="6d3e2-316">Once an interaction has started, relative motions of the hand may be used to control the gesture, as with the Manipulation or Navigation gesture.</span></span>

## <a name="see-also"></a><span data-ttu-id="6d3e2-317">関連項目</span><span class="sxs-lookup"><span data-stu-id="6d3e2-317">See also</span></span>
* [<span data-ttu-id="6d3e2-318">DirectX でのヘッド視線入力とアイ視線入力</span><span class="sxs-lookup"><span data-stu-id="6d3e2-318">Head and eye gaze in DirectX</span></span>](gaze-in-directx.md)
* [<span data-ttu-id="6d3e2-319">直接操作入力モデル</span><span class="sxs-lookup"><span data-stu-id="6d3e2-319">Direct manipulation input model</span></span>](../../design/direct-manipulation.md)
* [<span data-ttu-id="6d3e2-320">ポイントアンドコミット入力モデル</span><span class="sxs-lookup"><span data-stu-id="6d3e2-320">Point-and-commit input model</span></span>](../../design/point-and-commit.md)
* [<span data-ttu-id="6d3e2-321">入力モデルの宝石とコミット</span><span class="sxs-lookup"><span data-stu-id="6d3e2-321">Gaze and commit input model</span></span>](../../design/gaze-and-commit.md)
* [<span data-ttu-id="6d3e2-322">モーション コントローラー</span><span class="sxs-lookup"><span data-stu-id="6d3e2-322">Motion controllers</span></span>](../../design/motion-controllers.md)
